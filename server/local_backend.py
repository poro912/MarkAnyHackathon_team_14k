from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
import json
import uuid
import os
from datetime import datetime
from typing import List
from pydantic import BaseModel
from function_extractor import FunctionExtractor
import tempfile
import subprocess
import shutil
import git
from urllib.parse import urlparse
import stat

# í˜„ì¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

app.mount("/static", StaticFiles(directory=CURRENT_DIR), name="static")

# ë¡œì»¬ ì €ì¥ì†Œ ì„¤ì •
LOCAL_STORAGE_DIR = os.path.join(CURRENT_DIR, "local_storage")
LOCAL_BUILDS_DIR = os.path.join(LOCAL_STORAGE_DIR, "builds")
LOCAL_REPOS_DIR = os.path.join(LOCAL_STORAGE_DIR, "repositories")
LOCAL_DB_FILE = os.path.join(LOCAL_STORAGE_DIR, "builds.json")

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(LOCAL_BUILDS_DIR, exist_ok=True)
os.makedirs(LOCAL_REPOS_DIR, exist_ok=True)

# ë¡œì»¬ JSON DB ì´ˆê¸°í™”
if not os.path.exists(LOCAL_DB_FILE):
    with open(LOCAL_DB_FILE, 'w', encoding='utf-8') as f:
        json.dump([], f)

class BuildConfig(BaseModel):
    architecture: str
    runtime: str
    msvc_version: str
    library_type: str
    utilities: List[dict]
    comment: str = ""

class GitRepoRequest(BaseModel):
    repo_url: str
    repo_id: str

class CommitAnalysisRequest(BaseModel):
    repo_id: str
    commit_sha: str
    branch_name: str = ""

def save_to_local_db(build_data):
    """ë¡œì»¬ JSONì— ë¹Œë“œ ë°ì´í„° ì €ì¥"""
    try:
        with open(LOCAL_DB_FILE, 'r', encoding='utf-8') as f:
            builds = json.load(f)
    except:
        builds = []
    
    builds.append(build_data)
    
    with open(LOCAL_DB_FILE, 'w', encoding='utf-8') as f:
        json.dump(builds, f, ensure_ascii=False, indent=2)

def get_from_local_db():
    """ë¡œì»¬ JSONì—ì„œ ë¹Œë“œ ë°ì´í„° ì¡°íšŒ"""
    try:
        with open(LOCAL_DB_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return []

@app.get("/")
async def read_root():
    return FileResponse(os.path.join(CURRENT_DIR, "index.html"))

@app.get("/{filename}")
async def serve_html(filename: str):
    if filename.endswith('.html'):
        file_path = os.path.join(CURRENT_DIR, filename)
        if os.path.exists(file_path):
            return FileResponse(file_path)
    raise HTTPException(status_code=404)

# GitHub API í”„ë¡ì‹œ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/github/{path:path}")
async def github_proxy(path: str):
    """GitHub API í”„ë¡ì‹œ (CORS í•´ê²°)"""
    import httpx
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"https://api.github.com/{path}")
            return JSONResponse(
                content=response.json(),
                headers={"Access-Control-Allow-Origin": "*"}
            )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

def force_remove_readonly(func, path, exc):
    """ì½ê¸° ì „ìš© íŒŒì¼ ê°•ì œ ì‚­ì œ"""
    try:
        os.chmod(path, stat.S_IWRITE)
        func(path)
    except Exception:
        pass

@app.post("/analyze_github_repo")
async def analyze_github_repo(request: GitRepoRequest):
    """GitHub ë ˆí¬ì§€í„°ë¦¬ í´ë¡  ë° ë¶„ì„"""
    try:
        # ì˜êµ¬ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        repo_name = request.repo_id.replace('/', '_')
        repo_dir = os.path.join(LOCAL_REPOS_DIR, repo_name)
        
        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê°•ì œ ì‚­ì œ í›„ ì¬í´ë¡ 
        if os.path.exists(repo_dir):
            try:
                shutil.rmtree(repo_dir, onerror=force_remove_readonly)
            except Exception as e:
                print(f"ê¸°ì¡´ í´ë” ì‚­ì œ ì‹¤íŒ¨: {e}")
        
        # Git í´ë¡ 
        try:
            print(f"ğŸ“¥ í´ë¡  ì¤‘: {request.repo_url} -> {repo_dir}")
            git.Repo.clone_from(request.repo_url, repo_dir)
            print(f"âœ… í´ë¡  ì™„ë£Œ: {repo_dir}")
        except Exception as e:
            return {"error": f"ë ˆí¬ì§€í„°ë¦¬ í´ë¡  ì‹¤íŒ¨: {str(e)}"}
        
        # í”„ë¡œì íŠ¸ ë¶„ì„
        return analyze_project_directory(repo_dir)
            
    except Exception as e:
        return {"error": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

@app.post("/analyze_commit_changes")
async def analyze_commit_changes(request: CommitAnalysisRequest):
    """ì»¤ë°‹ ë³€ê²½ì‚¬í•­ ë¶„ì„"""
    try:
        # ë ˆí¬ì§€í„°ë¦¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        repo_name = request.repo_id.replace('/', '_')
        repo_dir = os.path.join(LOCAL_REPOS_DIR, repo_name)
        
        if not os.path.exists(repo_dir):
            return {"error": "ë ˆí¬ì§€í„°ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë ˆí¬ì§€í„°ë¦¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."}
        
        # Git ë ˆí¬ì§€í„°ë¦¬ ê°ì²´ ìƒì„±
        repo = git.Repo(repo_dir)
        
        # ì»¤ë°‹ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
        try:
            commit = repo.commit(request.commit_sha)
        except Exception as e:
            return {"error": f"ì»¤ë°‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"}
        
        # ì»¤ë°‹ì˜ ë³€ê²½ì‚¬í•­ ë¶„ì„
        files_data = []
        total_additions = 0
        total_deletions = 0
        difficulty_scores = []
        
        # ë¶€ëª¨ ì»¤ë°‹ê³¼ ë¹„êµí•˜ì—¬ ë³€ê²½ì‚¬í•­ ì¶”ì¶œ
        if commit.parents:
            parent_commit = commit.parents[0]
            diff = parent_commit.diff(commit, create_patch=True)
            
            for diff_item in diff:
                file_path = diff_item.a_path or diff_item.b_path
                if not file_path:
                    continue
                    
                file_ext = os.path.splitext(file_path)[1].lower()
                supported_extensions = {'.py', '.js', '.ts', '.java', '.cpp', '.c', '.cs', '.php', '.rb', '.go'}
                if file_ext not in supported_extensions:
                    continue
                
                try:
                    # Git statsë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ë³€ê²½ì‚¬í•­ í†µê³„ ê°€ì ¸ì˜¤ê¸°
                    stats = commit.stats.files.get(file_path, {'insertions': 0, 'deletions': 0})
                    added_lines = stats.get('insertions', 0)
                    deleted_lines = stats.get('deletions', 0)
                    
                    # diffê°€ ì—†ìœ¼ë©´ patchì—ì„œ ì§ì ‘ ê³„ì‚°
                    if added_lines == 0 and deleted_lines == 0 and diff_item.diff:
                        try:
                            diff_text = diff_item.diff.decode('utf-8', errors='ignore')
                            for line in diff_text.split('\n'):
                                if line.startswith('+') and not line.startswith('+++'):
                                    added_lines += 1
                                elif line.startswith('-') and not line.startswith('---'):
                                    deleted_lines += 1
                        except:
                            pass
                    
                    # í˜„ì¬ íŒŒì¼ ë‚´ìš© ë¶„ì„
                    current_content = ""
                    current_file_path = os.path.join(repo_dir, file_path)
                    if os.path.exists(current_file_path):
                        with open(current_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            current_content = f.read()
                    elif diff_item.b_blob:  # ìƒˆ íŒŒì¼ì¸ ê²½ìš°
                        current_content = diff_item.b_blob.data_stream.read().decode('utf-8', errors='ignore')
                    
                    if current_content or added_lines > 0:
                        file_analysis = analyze_commit_file_changes(
                            file_path, current_content, added_lines, deleted_lines
                        )
                        
                        if file_analysis:
                            files_data.append(file_analysis)
                            total_additions += added_lines
                            total_deletions += deleted_lines
                            difficulty_scores.append(file_analysis['difficulty_score'])
                
                except Exception as e:
                    print(f"íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜ {file_path}: {e}")
                    continue
        
        # ìš”ì•½ ì •ë³´ ê³„ì‚°
        summary = {
            'total_files': len(files_data),
            'total_additions': total_additions,
            'total_deletions': total_deletions,
            'avg_difficulty': round(sum(difficulty_scores) / len(difficulty_scores), 2) if difficulty_scores else 0
        }
        
        return {
            'summary': summary,
            'files': files_data,
            'commit_info': {
                'sha': request.commit_sha,
                'message': commit.message,
                'author': commit.author.name,
                'date': commit.committed_datetime.isoformat(),
                'branch': request.branch_name
            }
        }
        
    except Exception as e:
        return {"error": f"ì»¤ë°‹ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

def analyze_commit_file_changes(file_path, content, added_lines, deleted_lines):
    """ì»¤ë°‹ì—ì„œ ë³€ê²½ëœ íŒŒì¼ ë¶„ì„"""
    try:
        lines = content.split('\n')
        total_lines = len(lines)
        
        # ì½”ë“œ ë¼ì¸ê³¼ ì£¼ì„ ë¼ì¸ êµ¬ë¶„
        code_lines = 0
        comment_lines = 0
        
        for line in lines:
            stripped = line.strip()
            if not stripped:
                continue
            elif stripped.startswith('#') or stripped.startswith('//') or stripped.startswith('/*') or stripped.startswith('*'):
                comment_lines += 1
            else:
                code_lines += 1
        
        # ì¶”ê°€/ì‚­ì œëœ ë¼ì¸ì—ì„œ ì½”ë“œì™€ ì£¼ì„ êµ¬ë¶„ (ê°„ë‹¨í•œ ì¶”ì •)
        code_lines_added = max(0, int(added_lines * 0.8))  # 80%ê°€ ì½”ë“œë¼ê³  ê°€ì •
        comment_lines_added = added_lines - code_lines_added
        code_lines_deleted = max(0, int(deleted_lines * 0.8))
        comment_lines_deleted = deleted_lines - code_lines_deleted
        
        # ë³€ê²½ì‚¬í•­ ê¸°ë°˜ ë‚œì´ë„ ê³„ì‚°
        change_complexity = added_lines + deleted_lines
        file_complexity = calculate_complexity(content)
        
        # ë‚œì´ë„ ì ìˆ˜ (1-10)
        difficulty = min(10, max(1, 
            (change_complexity // 10) +  # ë³€ê²½ëŸ‰ ê¸°ë°˜
            (file_complexity // 20) +    # íŒŒì¼ ë³µì¡ë„ ê¸°ë°˜
            (1 if added_lines > deleted_lines else 0)  # ì¶”ê°€ê°€ ë” ë§ìœ¼ë©´ +1
        ))
        
        # ê°œë°œì ìˆ˜ì¤€ ì¶”ì •
        dev_level = get_developer_level(difficulty)
        
        return {
            'file_path': file_path,
            'code_lines': code_lines,
            'code_lines_added': code_lines_added,
            'code_lines_deleted': code_lines_deleted,
            'comment_lines': comment_lines,
            'comment_lines_added': comment_lines_added,
            'comment_lines_deleted': comment_lines_deleted,
            'difficulty_score': difficulty,
            'developer_level': dev_level,
            'total_additions': added_lines,
            'total_deletions': deleted_lines
        }
        
    except Exception as e:
        print(f"ì»¤ë°‹ íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None

@app.post("/analyze_project")
async def analyze_project(files: List[UploadFile] = File(...)):
    """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ ë¶„ì„"""
    try:
        # ì„ì‹œ ë””ë ‰í† ë¦¬ì— íŒŒì¼ë“¤ ì €ì¥
        with tempfile.TemporaryDirectory() as temp_dir:
            for file in files:
                file_path = os.path.join(temp_dir, file.filename)
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                
                content = await file.read()
                with open(file_path, 'wb') as f:
                    f.write(content)
            
            # í”„ë¡œì íŠ¸ ë¶„ì„
            return analyze_project_directory(temp_dir)
            
    except Exception as e:
        return {"error": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

def analyze_project_directory(project_dir):
    """í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ë¶„ì„"""
    extractor = FunctionExtractor()
    files_data = []
    total_lines = 0
    total_files = 0
    complexity_scores = []
    difficulty_scores = []
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ì
    supported_extensions = {'.py', '.js', '.ts', '.java', '.cpp', '.c', '.cs', '.php', '.rb', '.go'}
    
    for root, dirs, files in os.walk(project_dir):
        # ë¶ˆí•„ìš”í•œ ë””ë ‰í† ë¦¬ ì œì™¸
        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'build', 'dist']]
        
        for file in files:
            file_path = os.path.join(root, file)
            file_ext = os.path.splitext(file)[1].lower()
            
            if file_ext in supported_extensions:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # íŒŒì¼ ë¶„ì„
                    file_analysis = analyze_file(file_path, content, extractor)
                    if file_analysis:
                        files_data.append(file_analysis)
                        total_lines += file_analysis['total_lines']
                        total_files += 1
                        complexity_scores.append(file_analysis['cyclomatic_complexity'])
                        difficulty_scores.append(file_analysis['difficulty_score'])
                        
                except Exception as e:
                    print(f"íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜ {file_path}: {e}")
                    continue
    
    # ìš”ì•½ ì •ë³´ ê³„ì‚°
    summary = {
        'total_files': total_files,
        'total_lines': total_lines,
        'avg_complexity': round(sum(complexity_scores) / len(complexity_scores), 2) if complexity_scores else 0,
        'max_difficulty': max(difficulty_scores) if difficulty_scores else 0,
        'total_estimated_hours': sum(f['estimated_dev_hours'] for f in files_data)
    }
    
    return {
        'summary': summary,
        'files': files_data
    }

def analyze_file(file_path, content, extractor):
    """ê°œë³„ íŒŒì¼ ë¶„ì„"""
    try:
        lines = content.split('\n')
        total_lines = len(lines)
        code_lines = len([line for line in lines if line.strip() and not line.strip().startswith('#') and not line.strip().startswith('//')])
        comment_lines = total_lines - code_lines
        comment_ratio = f"{round((comment_lines / total_lines) * 100, 1)}%" if total_lines > 0 else "0%"
        
        # ë³µì¡ë„ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        complexity = calculate_complexity(content)
        
        # ê¸°ìˆ  ìŠ¤íƒ ê°ì§€
        tech_stack = detect_tech_stack(file_path, content)
        
        # ë‚œì´ë„ ì ìˆ˜ (1-10)
        difficulty = min(10, max(1, complexity // 5 + len(tech_stack)))
        
        # ê°œë°œì ìˆ˜ì¤€ ì¶”ì •
        dev_level = get_developer_level(difficulty)
        
        # ì˜ˆìƒ ê°œë°œ ì‹œê°„ (ì‹œê°„)
        estimated_hours = max(1, (code_lines // 50) + (complexity // 10))
        
        return {
            'file_path': os.path.relpath(file_path),
            'total_lines': total_lines,
            'code_lines': code_lines,
            'code_comment_ratio': comment_ratio,
            'cyclomatic_complexity': complexity,
            'maintainability_index': max(0, min(100, 100 - complexity)),
            'estimated_dev_hours': estimated_hours,
            'difficulty_score': difficulty,
            'developer_level': dev_level,
            'pattern_score': min(10, max(1, 8 - (complexity // 10))),
            'optimization_score': min(10, max(1, 7 + (comment_lines // 10))),
            'best_practices_score': min(10, max(1, 6 + len(tech_stack))),
            'tech_stack': tech_stack
        }
    except Exception as e:
        print(f"íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None

def calculate_complexity(content):
    """ì½”ë“œ ë³µì¡ë„ ê³„ì‚°"""
    complexity = 1  # ê¸°ë³¸ ë³µì¡ë„
    
    # ì œì–´ êµ¬ì¡° ì¹´ìš´íŠ¸
    control_keywords = ['if', 'else', 'elif', 'for', 'while', 'switch', 'case', 'try', 'catch', 'except']
    for keyword in control_keywords:
        complexity += content.lower().count(keyword)
    
    # í•¨ìˆ˜/ë©”ì„œë“œ ì¹´ìš´íŠ¸
    complexity += content.count('def ') + content.count('function ') + content.count('public ') + content.count('private ')
    
    return min(100, complexity)

def detect_tech_stack(file_path, content):
    """ê¸°ìˆ  ìŠ¤íƒ ê°ì§€"""
    tech_stack = []
    file_ext = os.path.splitext(file_path)[1].lower()
    
    # íŒŒì¼ í™•ì¥ì ê¸°ë°˜
    ext_mapping = {
        '.py': 'Python',
        '.js': 'JavaScript',
        '.ts': 'TypeScript',
        '.java': 'Java',
        '.cpp': 'C++',
        '.c': 'C',
        '.cs': 'C#',
        '.php': 'PHP',
        '.rb': 'Ruby',
        '.go': 'Go'
    }
    
    if file_ext in ext_mapping:
        tech_stack.append(ext_mapping[file_ext])
    
    # í”„ë ˆì„ì›Œí¬/ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°ì§€
    frameworks = {
        'react': 'React',
        'vue': 'Vue.js',
        'angular': 'Angular',
        'django': 'Django',
        'flask': 'Flask',
        'spring': 'Spring',
        'express': 'Express.js',
        'jquery': 'jQuery'
    }
    
    content_lower = content.lower()
    for keyword, framework in frameworks.items():
        if keyword in content_lower:
            tech_stack.append(framework)
    
    return list(set(tech_stack))  # ì¤‘ë³µ ì œê±°

def get_developer_level(difficulty):
    """ë‚œì´ë„ ê¸°ë°˜ ê°œë°œì ìˆ˜ì¤€ ì¶”ì •"""
    if difficulty <= 3:
        return "ì´ˆê¸‰"
    elif difficulty <= 6:
        return "ì¤‘ê¸‰"
    elif difficulty <= 8:
        return "ê³ ê¸‰"
    else:
        return "ì „ë¬¸ê°€"

@app.post("/analyze")
async def analyze_code(files: List[UploadFile] = File(...)):
    extractor = FunctionExtractor()
    utilities = []
    
    for file in files:
        try:
            content = await file.read()
            try:
                text = content.decode('utf-8')
            except:
                text = content.decode('cp949', errors='ignore')
            
            functions = extractor.extract_functions(text)
            for func in functions:
                func['source_file'] = file.filename
            utilities.extend(functions)
            
        except Exception as e:
            print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            continue
    
    return {"utilities": utilities}

@app.post("/build")
async def build_dll(config: BuildConfig):
    build_id = str(uuid.uuid4())
    file_extension = "dll" if config.library_type == "dll" else "lib"
    
    # í—¤ë” íŒŒì¼ ìƒì„±
    header_content = generate_header_file(config.utilities, config.library_type)
    
    # C++ ì†ŒìŠ¤ íŒŒì¼ ìƒì„±
    cpp_content = "#include <iostream>\n"
    if config.library_type == "dll":
        cpp_content += '#define LIBRARY_API __declspec(dllexport)\n'
    else:
        cpp_content += '#define LIBRARY_API\n'
    
    for utility in config.utilities:
        cpp_content += f"\n{utility.get('code', '// ì½”ë“œ ì—†ìŒ')}\n"
    
    # ì„ì‹œ íŒŒì¼ë¡œ ì»´íŒŒì¼
    with tempfile.TemporaryDirectory() as temp_dir:
        cpp_file = os.path.join(temp_dir, f"{build_id}.cpp")
        dll_file = os.path.join(temp_dir, f"{build_id}.{file_extension}")
        
        with open(cpp_file, 'w', encoding='utf-8') as f:
            f.write(cpp_content)
        
        try:
            # g++ ì»´íŒŒì¼
            if config.library_type == "dll":
                compile_cmd = ["g++", "-shared", "-fPIC", "-std=c++17", "-o", dll_file, cpp_file]
            else:
                obj_file = cpp_file.replace('.cpp', '.o')
                subprocess.run(["g++", "-c", "-std=c++17", "-o", obj_file, cpp_file], check=True)
                compile_cmd = ["ar", "rcs", dll_file.replace('.lib', '.a'), obj_file]
            
            result = subprocess.run(compile_cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                # ë¡œì»¬ì— ì €ì¥
                local_dll_path = os.path.join(LOCAL_BUILDS_DIR, f"{build_id}.{file_extension}")
                local_header_path = os.path.join(LOCAL_BUILDS_DIR, f"{build_id}.h")
                
                with open(dll_file, 'rb') as src, open(local_dll_path, 'wb') as dst:
                    dst.write(src.read())
                
                with open(local_header_path, 'w', encoding='utf-8') as f:
                    f.write(header_content)
                
                # ë¹Œë“œ ì •ë³´ ì €ì¥
                build_data = {
                    'build_id': build_id,
                    'filename': f"{build_id}.{file_extension}",
                    'header_filename': f"{build_id}.h",
                    'comment': config.comment,
                    'status': 'completed',
                    'local_dll_path': local_dll_path,
                    'local_header_path': local_header_path,
                    'utilities': config.utilities,
                    'timestamp': datetime.now().isoformat()
                }
                
                save_to_local_db(build_data)
                
                return {
                    "build_id": build_id,
                    "status": "completed",
                    "message": "ë¹Œë“œ ì™„ë£Œ",
                    "file_extension": file_extension
                }
            else:
                raise Exception(f"ì»´íŒŒì¼ ì‹¤íŒ¨: {result.stderr}")
                
        except Exception as e:
            return {"error": f"ë¹Œë“œ ì‹¤íŒ¨: {str(e)}"}

@app.get("/builds")
async def get_builds():
    builds = get_from_local_db()
    for build in builds:
        build_id = build.get('build_id')
        if build_id:
            build['dll_download_url'] = f"/download/{build_id}"
            build['header_download_url'] = f"/download/{build_id}/header"
    return {"builds": builds}

@app.get("/download/{build_id}")
async def download_library(build_id: str):
    builds = get_from_local_db()
    build = next((b for b in builds if b.get('build_id') == build_id), None)
    
    if not build:
        raise HTTPException(status_code=404, detail="ë¹Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    dll_path = build.get('local_dll_path')
    if not dll_path or not os.path.exists(dll_path):
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    return FileResponse(dll_path, filename=build.get('filename'))

@app.get("/download/{build_id}/header")
async def download_header(build_id: str):
    builds = get_from_local_db()
    build = next((b for b in builds if b.get('build_id') == build_id), None)
    
    if not build:
        raise HTTPException(status_code=404, detail="ë¹Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    header_path = build.get('local_header_path')
    if not header_path or not os.path.exists(header_path):
        raise HTTPException(status_code=404, detail="í—¤ë” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    return FileResponse(header_path, filename=build.get('header_filename'))

def generate_header_file(utilities, library_type):
    header = f"""#ifndef UTILITY_LIBRARY_H
#define UTILITY_LIBRARY_H

#ifdef __cplusplus
extern "C" {{
#endif

{"#define LIBRARY_API __declspec(dllexport)" if library_type == "dll" else "#define LIBRARY_API"}

"""
    
    for utility in utilities:
        func_name = utility.get('name', 'Unknown')
        params = utility.get('parameters', 'void')
        return_type = utility.get('return_type', 'void').split(' - ')[0].strip()
        header += f"LIBRARY_API {return_type} {func_name}({params});\n"
    
    header += """
#ifdef __cplusplus
}
#endif

#endif // UTILITY_LIBRARY_H
"""
    return header

if __name__ == "__main__":
    import uvicorn
    import platform
    
    # í™˜ê²½ ê°ì§€
    is_windows = platform.system() == "Windows"
    
    if is_windows:
        # ìœˆë„ìš° í™˜ê²½
        host = "127.0.0.1"
        print("ğŸš€ ìœˆë„ìš° ë¡œì»¬ í™˜ê²½ì—ì„œ ì„œë²„ ì‹œì‘")
    else:
        # AWS/Linux í™˜ê²½
        host = "0.0.0.0"
        print("ğŸš€ AWS/Linux í™˜ê²½ì—ì„œ ì„œë²„ ì‹œì‘")
    
    print("ğŸ’» ê¸°ë³¸ ê¸°ëŠ¥ í™œì„±í™”")
    print(f"ğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost ì ‘ì†í•˜ì„¸ìš”")
    uvicorn.run(app, host=host, port=80)