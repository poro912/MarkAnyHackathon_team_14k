from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse, HTMLResponse, Response
from fastapi.staticfiles import StaticFiles
import json
import uuid
import os
from datetime import datetime
from typing import List
from pydantic import BaseModel
from decimal import Decimal
from function_extractor import FunctionExtractor
from agents.agent_wrapper import AgentWrapper
from code_analyzer import CodeAnalyzer
import git
import stat
import httpx
import json
import shutil
import git
import stat

def decimal_default(obj):
    """DynamoDB Decimal íƒ€ì…ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë³€í™˜"""
    if isinstance(obj, Decimal):
        return int(obj) if obj % 1 == 0 else float(obj)
    raise TypeError
from aws_config import *
import tempfile

# í˜„ì¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
import os

app = FastAPI()

# ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì •
app.mount("/static", StaticFiles(directory=CURRENT_DIR), name="static")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì„œë¹™ - HTML íŒŒì¼ë“¤ì„ ë£¨íŠ¸ì—ì„œ ì§ì ‘ ì„œë¹™
# app.mount("/static", StaticFiles(directory="."), name="static")

# Agent ë˜í¼ ì´ˆê¸°í™”
try:
    init_aws_resources()
    agent_wrapper = AgentWrapper()
    code_analyzer = CodeAnalyzer()
    print("Agent ë˜í¼ ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    print(f"AWS ì´ˆê¸°í™” ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
    agent_wrapper = None
    code_analyzer = CodeAnalyzer()

# ë¡œì»¬ ì €ì¥ì†Œ ì„¤ì • (AWS í™˜ê²½ìš©)
LOCAL_STORAGE_DIR = os.path.join(CURRENT_DIR, "local_storage")
LOCAL_REPOS_DIR = os.path.join(LOCAL_STORAGE_DIR, "repositories")
LOCAL_BUILDS_DIR = os.path.join(LOCAL_STORAGE_DIR, "builds")
os.makedirs(LOCAL_REPOS_DIR, exist_ok=True)
os.makedirs(LOCAL_BUILDS_DIR, exist_ok=True)
os.makedirs(LOCAL_STORAGE_DIR, exist_ok=True)

class BuildConfig(BaseModel):
    architecture: str
    runtime: str
    msvc_version: str
    library_type: str
    utilities: List[dict]  # ì‹¤ì œ í•¨ìˆ˜ ë°ì´í„°
    comment: str = ""

class GitRepoRequest(BaseModel):
    repo_url: str
    repo_id: str

class CommitAnalysisRequest(BaseModel):
    repo_id: str
    commit_sha: str
    branch_name: str = ""

class FileContentRequest(BaseModel):
    file_path: str
    repo_id: str = None

class CommitFileDiffRequest(BaseModel):
    file_path: str
    repo_id: str = None
    commit_sha: str = None

class FeedbackRequest(BaseModel):
    file_name: str
    file_data: dict
    file_content: str = ""
    user_difficulty: int
    ai_difficulty: int
    feedback_reason: str

def force_remove_readonly(func, path, exc):
    """ì½ê¸° ì „ìš© íŒŒì¼ ê°•ì œ ì‚­ì œ"""
    try:
        os.chmod(path, stat.S_IWRITE)
        func(path)
    except Exception:
        pass

@app.get("/test.html")
async def serve_test():
    response = FileResponse("test.html")
    response.headers["X-Frame-Options"] = "SAMEORIGIN"
    return response

@app.get("/system_info.html")
async def serve_system_info():
    response = FileResponse("system_info.html")
    response.headers["X-Frame-Options"] = "SAMEORIGIN"
    return response

@app.get("/project_evaluation.html")
async def serve_project_evaluation():
    response = FileResponse("project_evaluation.html")
    response.headers["X-Frame-Options"] = "SAMEORIGIN"
    return response

@app.get("/advanced_utility_extractor.html")
async def serve_advanced_utility_extractor():
    response = FileResponse("advanced_utility_extractor.html")
    response.headers["X-Frame-Options"] = "SAMEORIGIN"
    return response

@app.delete("/clear_test_data")
async def clear_test_data():
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚­ì œ"""
    try:
        table = dynamodb.Table(DYNAMODB_TABLE_NAME)
        
        # í…ŒìŠ¤íŠ¸.cpp íŒŒì¼ì˜ ëª¨ë“  í•­ëª© ìŠ¤ìº”
        response = table.scan(
            FilterExpression="contains(#file, :test_file)",
            ExpressionAttributeNames={'#file': 'file'},
            ExpressionAttributeValues={':test_file': 'í…ŒìŠ¤íŠ¸.cpp'}
        )
        
        # ê° í•­ëª© ì‚­ì œ
        for item in response['Items']:
            table.delete_item(Key={'id': item['id']})
        
        return {"success": True, "deleted_count": len(response['Items'])}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/save_extraction")
async def save_extraction(function_data: dict):
    """ì¶”ì¶œëœ í•¨ìˆ˜ë¥¼ íˆìŠ¤í† ë¦¬ì— ì €ì¥"""
    try:
        # í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
        from datetime import datetime, timezone, timedelta
        kst = timezone(timedelta(hours=9))
        current_time = datetime.now(kst)
        
        function_data['timestamp'] = current_time.isoformat()
        function_data['extracted_at'] = current_time.strftime('%Y-%m-%d %H:%M:%S')
        
        # DynamoDBì— ì €ì¥
        table = dynamodb.Table(DYNAMODB_TABLE_NAME)
        function_data['id'] = str(uuid.uuid4())
        
        table.put_item(Item=function_data)
        
        return {"success": True, "message": "ì¶”ì¶œ íˆìŠ¤í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤"}
    except Exception as e:
        print(f"ì¶”ì¶œ íˆìŠ¤í† ë¦¬ ì €ì¥ ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.post("/analyze")
async def analyze_code(files: List[UploadFile] = File(...)):
    extractor = FunctionExtractor()
    new_utilities = []
    
    for file in files:
        try:
            print(f"íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file.filename}")
            
            # íŒŒì¼ ì½ê¸°
            content = await file.read()
            print(f"íŒŒì¼ í¬ê¸°: {len(content)} bytes")
            
            # í…ìŠ¤íŠ¸ ë””ì½”ë”©
            try:
                text = content.decode('utf-8')
            except UnicodeDecodeError:
                try:
                    text = content.decode('cp949')
                except UnicodeDecodeError:
                    text = content.decode('latin-1')
            
            print(f"ë””ì½”ë”©ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
            
            # íŒŒì¼ í™•ì¥ì í™•ì¸
            file_extension = file.filename.split('.')[-1] if '.' in file.filename else 'txt'
            print(f"íŒŒì¼ í™•ì¥ì: .{file_extension}")
            
            # 1ë‹¨ê³„: ìˆ˜ë™ í•¨ìˆ˜ ì¶”ì¶œ (ì •í™•í•œ ì‹œê·¸ë‹ˆì²˜)
            print(f"1ë‹¨ê³„ - í•¨ìˆ˜ ì¶”ì¶œ: {file.filename}")
            raw_functions = extractor.extract_functions(text)
            print(f"ì¶”ì¶œëœ ì›ë³¸ í•¨ìˆ˜: {len(raw_functions)}ê°œ")
            
            # 2ë‹¨ê³„: AI ë¦¬íŒ©í† ë§ (ì¬ì‚¬ìš©ì„± í–¥ìƒ)
            if agent_wrapper and raw_functions:
                print(f"2ë‹¨ê³„ - AI ë¦¬íŒ©í† ë§: {file.filename}")
                utilities = await agent_wrapper.refactor_for_reusability(raw_functions, text, file_extension)
                print(f"ë¦¬íŒ©í† ë§ëœ í•¨ìˆ˜: {len(utilities)}ê°œ")
            else:
                utilities = raw_functions
                print("AI ì—†ì´ ì›ë³¸ í•¨ìˆ˜ ì‚¬ìš©")
            
            # íŒŒì¼ ì •ë³´ ì¶”ê°€
            for util in utilities:
                util['source_file'] = file.filename
                util['file_extension'] = file_extension
            
            new_utilities.extend(utilities)
            
        except Exception as e:
            print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({file.filename}): {e}")
            continue
    
    # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ì™€ í•©ì¹˜ê¸°
    try:
        # ì„¸ì…˜ì—ì„œ ê¸°ì¡´ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì €ì¥ì†Œ ì‚¬ìš©)
        if not hasattr(app.state, 'analyzed_utilities'):
            app.state.analyzed_utilities = []
        
        # ì¤‘ë³µ ì œê±°: ê°™ì€ íŒŒì¼ì˜ ê°™ì€ í•¨ìˆ˜ëª…ì€ ìƒˆ ê²ƒìœ¼ë¡œ êµì²´
        existing_utilities = app.state.analyzed_utilities.copy()
        
        for new_util in new_utilities:
            # ê°™ì€ íŒŒì¼ì˜ ê°™ì€ í•¨ìˆ˜ê°€ ìˆìœ¼ë©´ ì œê±°
            existing_utilities = [
                util for util in existing_utilities 
                if not (util.get('source_file') == new_util.get('source_file') and 
                       util.get('name') == new_util.get('name'))
            ]
        
        # ìƒˆ í•¨ìˆ˜ë“¤ ì¶”ê°€
        all_utilities = existing_utilities + new_utilities
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        app.state.analyzed_utilities = all_utilities
        
        # ì¶”ì¶œ íˆìŠ¤í† ë¦¬ì— ìƒˆë¡œ ì¶”ì¶œëœ í•¨ìˆ˜ë“¤ ì €ì¥
        if new_utilities:
            try:
                dynamodb = get_dynamodb_client()
                table = dynamodb.Table(DYNAMODB_TABLE_NAME)
                
                from datetime import timezone, timedelta
                # í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
                kst = timezone(timedelta(hours=9))
                
                # ê° í•¨ìˆ˜ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì €ì¥
                for utility in new_utilities:
                    function_id = str(uuid.uuid4())
                    table.put_item(
                        Item={
                            'id': function_id,
                            'type': 'function',  # í•¨ìˆ˜ íƒ€ì… êµ¬ë¶„
                            'name': utility.get('name', 'Unknown'),
                            'description': utility.get('description', ''),
                            'purpose': utility.get('purpose', ''),
                            'parameters': utility.get('parameters', ''),
                            'return_type': utility.get('return_type', ''),
                            'code': utility.get('code', ''),
                            'timestamp': datetime.now(kst).isoformat(),
                            'build_id': 'extracted_only',  # ì¶”ì¶œë§Œ ëœ í•¨ìˆ˜ í‘œì‹œ
                            'comment': f"{utility.get('source_file', 'Unknown')}ì—ì„œ ì¶”ì¶œë¨"
                        }
                    )
                print(f"âœ… {len(new_utilities)}ê°œ í•¨ìˆ˜ê°€ ì¶”ì¶œ íˆìŠ¤í† ë¦¬ì— ì €ì¥ë¨")
            except Exception as e:
                print(f"ì¶”ì¶œ íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        print(f"ğŸ“Š ì „ì²´ í•¨ìˆ˜: {len(all_utilities)}ê°œ (ê¸°ì¡´: {len(existing_utilities)}ê°œ, ìƒˆë¡œ ì¶”ê°€: {len(new_utilities)}ê°œ)")
        
        return {"utilities": all_utilities}
        
    except Exception as e:
        print(f"ê²°ê³¼ í•©ì¹˜ê¸° ì˜¤ë¥˜: {e}")
        return {"utilities": new_utilities}

@app.get("/agent/stats")
async def get_agent_stats():
    """Agent í†µê³„ ì •ë³´ ì¡°íšŒ"""
    if not agent_wrapper:
        return {"error": "Agentê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    
    return await agent_wrapper.get_agent_stats()

@app.get("/utilities")
async def get_saved_utilities():
    # DynamoDBì—ì„œ ì €ì¥ëœ ìœ í‹¸ë¦¬í‹° ì¡°íšŒ
    dynamodb = get_dynamodb_client()
    table = dynamodb.Table(DYNAMODB_TABLE_NAME)
    
    try:
        response = table.scan()
        utilities = []
        for item in response['Items']:
            if 'utilities' in item:
                utilities.extend(item['utilities'])
        return {"utilities": utilities}
    except Exception as e:
        return {"utilities": []}

@app.post("/build")
async def build_dll(config: BuildConfig):
    print(f"ğŸ—ï¸ ë¹Œë“œ ìš”ì²­ ë°›ìŒ: {len(config.utilities)}ê°œ í•¨ìˆ˜")
    
    # ë°›ì€ ë°ì´í„° í™•ì¸
    for i, utility in enumerate(config.utilities):
        print(f"  í•¨ìˆ˜ {i+1}: {utility.get('name', 'Unknown')}")
        print(f"    header_declaration ì¡´ì¬: {'header_declaration' in utility}")
        if 'header_declaration' in utility:
            print(f"    header_declaration: {utility['header_declaration']}")
        else:
            print(f"    ì‚¬ìš© ê°€ëŠ¥í•œ í•„ë“œë“¤: {list(utility.keys())}")
    
    build_id = str(uuid.uuid4())
    
    # ë¼ì´ë¸ŒëŸ¬ë¦¬ íƒ€ì…ì— ë”°ë¥¸ íŒŒì¼ í™•ì¥ì ê²°ì •
    file_extension = "dll" if config.library_type == "dll" else "lib"
    
    # í—¤ë” íŒŒì¼ ìƒì„±
    header_content = generate_header_file(config.utilities, config.library_type)
    
    # ì‹¤ì œ C++ ì†ŒìŠ¤ íŒŒì¼ ìƒì„±
    # ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ì—ì„œ í—¤ë” ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    all_headers = set()
    
    # ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ì™€ ë§¤ì¹­í•˜ì—¬ required_headers ì°¾ê¸°
    stored_utilities = getattr(app.state, 'analyzed_utilities', [])
    
    for utility in config.utilities:
        func_name = utility.get('name')
        
        # ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ì—ì„œ ê°™ì€ í•¨ìˆ˜ ì°¾ê¸°
        stored_util = None
        for stored in stored_utilities:
            if stored.get('name') == func_name:
                stored_util = stored
                break
        
        if stored_util and 'required_headers' in stored_util:
            required_headers = stored_util.get('required_headers', [])
            all_headers.update(required_headers)
            print(f"ğŸ“‹ {func_name}: AI ì œê³µ í—¤ë” {required_headers}")
        else:
            print(f"âš ï¸ {func_name}: ì €ì¥ëœ í—¤ë” ì •ë³´ ì—†ìŒ, ì½”ë“œì—ì„œ ì¶”ì¶œ")
            # ë°±ì—…: ì½”ë“œì—ì„œ í—¤ë” ìë™ ê°ì§€
            code = utility.get('code', '')
            if 'std::chrono' in code or 'system_clock' in code or 'time_point' in code:
                all_headers.add('<chrono>')
            if 'std::put_time' in code or 'std::setw' in code or 'std::setfill' in code:
                all_headers.add('<iomanip>')
            if 'std::ostringstream' in code or 'std::stringstream' in code:
                all_headers.add('<sstream>')
            if 'std::pow' in code or 'std::sqrt' in code:
                all_headers.add('<cmath>')
            if 'localtime_s' in code or 'localtime_r' in code:
                all_headers.add('<ctime>')
            if 'std::string' in code:
                all_headers.add('<string>')
            if 'std::optional' in code:
                all_headers.add('<optional>')
            if 'std::filesystem' in code or 'filesystem::path' in code:
                all_headers.add('<filesystem>')
            if 'std::ifstream' in code or 'std::ofstream' in code or 'std::fstream' in code:
                all_headers.add('<fstream>')
            if 'std::runtime_error' in code or 'std::exception' in code:
                all_headers.add('<stdexcept>')
    
    # ê¸°ë³¸ í—¤ë”ë“¤ ì¶”ê°€
    default_headers = ['<iostream>']
    all_headers.update(default_headers)
    
    print(f"ğŸ”§ ìµœì¢… í¬í•¨ëœ í—¤ë”ë“¤: {sorted(all_headers)}")
    
    cpp_content = ""
    
    # í—¤ë” í¬í•¨
    for header in sorted(all_headers):
        cpp_content += f"#include {header}\n"
    
    cpp_content += f"""
#ifdef _WIN32
#define LIBRARY_API __declspec(dllexport)
#else
#define LIBRARY_API __attribute__((visibility("default")))
#endif

"""
    
    # ê° í•¨ìˆ˜ì˜ ì½”ë“œ ì¶”ê°€
    for utility in config.utilities:
        cpp_content += f"""
{utility.get('code', '// ì½”ë“œ ì—†ìŒ')}

"""
    
    # ì„ì‹œ íŒŒì¼ ìƒì„± ë° ì»´íŒŒì¼
    import tempfile
    import subprocess
    import os
    
    with tempfile.TemporaryDirectory() as temp_dir:
        cpp_file = os.path.join(temp_dir, f"{build_id}.cpp")
        dll_file = os.path.join(temp_dir, f"{build_id}.{file_extension}")
        
        # C++ íŒŒì¼ ì‘ì„±
        with open(cpp_file, 'w', encoding='utf-8') as f:
            f.write(cpp_content)
        
        print(f"ğŸ”¨ C++ ì»´íŒŒì¼ ì‹œì‘: {cpp_file}")
        
        try:
            # g++ ì»´íŒŒì¼ (Linux í™˜ê²½)
            if config.library_type == "dll":
                compile_cmd = [
                    "g++", "-shared", "-fPIC", "-std=c++17",
                    "-o", dll_file, cpp_file
                ]
            else:
                compile_cmd = [
                    "ar", "rcs", dll_file.replace('.lib', '.a'),
                    cpp_file.replace('.cpp', '.o')
                ]
                # ë¨¼ì € ì˜¤ë¸Œì íŠ¸ íŒŒì¼ ìƒì„±
                obj_cmd = ["g++", "-c", "-std=c++17", "-o", cpp_file.replace('.cpp', '.o'), cpp_file]
                subprocess.run(obj_cmd, check=True, cwd=temp_dir)
            
            result = subprocess.run(compile_cmd, capture_output=True, text=True, cwd=temp_dir)
            
            if result.returncode == 0:
                print(f"âœ… ì»´íŒŒì¼ ì„±ê³µ!")
                
                # ì»´íŒŒì¼ëœ íŒŒì¼ ì½ê¸°
                with open(dll_file, 'rb') as f:
                    library_content = f.read()
                    
                # ë¡œì»¬ì— ì„ì‹œ ì €ì¥
                local_dir = "/tmp/builds"
                os.makedirs(local_dir, exist_ok=True)
                
                local_dll_path = os.path.join(local_dir, f"{build_id}.{file_extension}")
                local_header_path = os.path.join(local_dir, f"{build_id}.h")
                
                with open(local_dll_path, 'wb') as f:
                    f.write(library_content)
                    
                with open(local_header_path, 'w', encoding='utf-8') as f:
                    f.write(header_content)
                    
                print(f"ğŸ“ ë¡œì»¬ ì €ì¥ ì™„ë£Œ: {local_dll_path}")
                
                # S3 ì—…ë¡œë“œ
                s3 = get_s3_client()
                
                # DLL íŒŒì¼ ì—…ë¡œë“œ
                s3.put_object(
                    Bucket=S3_BUCKET_NAME,
                    Key=f"{build_id}.{file_extension}",
                    Body=library_content,
                    ContentType='application/octet-stream'
                )
                
                # í—¤ë” íŒŒì¼ ì—…ë¡œë“œ
                s3.put_object(
                    Bucket=S3_BUCKET_NAME,
                    Key=f"{build_id}.h",
                    Body=header_content.encode('utf-8'),
                    ContentType='text/plain'
                )
                
                print(f"â˜ï¸ S3 ì—…ë¡œë“œ ì™„ë£Œ: {build_id}")
                
            else:
                print(f"âŒ ì»´íŒŒì¼ ì‹¤íŒ¨: {result.stderr}")
                library_content = f"// ì»´íŒŒì¼ ì‹¤íŒ¨: {result.stderr}".encode()
                local_dll_path = None  # ì»´íŒŒì¼ ì‹¤íŒ¨ ì‹œ None
                local_header_path = None
                
        except Exception as e:
            print(f"âŒ ì»´íŒŒì¼ ì˜¤ë¥˜: {e}")
            library_content = f"// ì»´íŒŒì¼ ì˜¤ë¥˜: {str(e)}".encode()
            local_dll_path = None  # ì»´íŒŒì¼ ì˜¤ë¥˜ ì‹œ None
            local_header_path = None
    
    # S3 URL ìƒì„±
    s3_url = f"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{build_id}.{file_extension}"
    header_url = f"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{build_id}.h"
    
    # DynamoDBì— ë¹Œë“œ ì •ë³´ ì €ì¥ (ì—…ë¡œë“œ ì „ ìƒíƒœ)
    dynamodb = get_dynamodb_client()
    table = dynamodb.Table(DYNAMODB_TABLE_NAME)
    
    table.put_item(
        Item={
            'build_id': build_id,
            'filename': f"{build_id}.{file_extension}",
            'header_filename': f"{build_id}.h",
            'comment': config.comment,
            's3_url': s3_url,
            'header_url': header_url,
            'status': 'completed',  # ì—…ë¡œë“œ ì™„ë£Œ
            'local_dll_path': local_dll_path,
            'local_header_path': local_header_path,
            'build_config': config.model_dump(),
            'utilities': config.utilities,
            'timestamp': datetime.now().isoformat()
        }
    )
    
    return {
        "build_id": build_id, 
        "status": "built",
        "message": "ë¹Œë“œ ì™„ë£Œ. ì—…ë¡œë“œí•˜ë ¤ë©´ /upload ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
        "file_extension": file_extension
    }

@app.post("/clear")
async def clear_analysis():
    """ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”"""
    if hasattr(app.state, 'analyzed_utilities'):
        count = len(app.state.analyzed_utilities)
        app.state.analyzed_utilities = []
        print(f"ğŸ—‘ï¸ ë¶„ì„ ê²°ê³¼ ì´ˆê¸°í™”: {count}ê°œ í•¨ìˆ˜ ì‚­ì œ")
        return {"message": f"{count}ê°œ í•¨ìˆ˜ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.", "utilities": []}
    else:
        return {"message": "ì‚­ì œí•  ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", "utilities": []}

@app.get("/analyzed")
async def get_analyzed():
    """í˜„ì¬ ë¶„ì„ëœ í•¨ìˆ˜ ëª©ë¡ ì¡°íšŒ"""
    if hasattr(app.state, 'analyzed_utilities'):
        utilities = app.state.analyzed_utilities
        print(f"ğŸ“‹ í˜„ì¬ ë¶„ì„ëœ í•¨ìˆ˜: {len(utilities)}ê°œ")
        return {"utilities": utilities}
    else:
        return {"utilities": []}

@app.post("/upload/{build_id}")
async def upload_build(build_id: str, comment: str = ""):
    """ë¹Œë“œëœ íŒŒì¼ì„ S3ì— ì—…ë¡œë“œ"""
    print(f"ğŸ“¤ ì—…ë¡œë“œ ìš”ì²­: {build_id}")
    
    # DynamoDBì—ì„œ ë¹Œë“œ ì •ë³´ ì¡°íšŒ
    dynamodb = get_dynamodb_client()
    table = dynamodb.Table(DYNAMODB_TABLE_NAME)
    
    try:
        response = table.get_item(Key={'build_id': build_id})
        if 'Item' not in response:
            return {"error": "ë¹Œë“œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        build_info = response['Item']
        
        if build_info.get('status') != 'built':
            return {"error": "ì—…ë¡œë“œ ê°€ëŠ¥í•œ ë¹Œë“œê°€ ì•„ë‹™ë‹ˆë‹¤."}
        
        # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
        local_dll_path = build_info.get('local_dll_path')
        local_header_path = build_info.get('local_header_path')
        
        if not os.path.exists(local_dll_path) or not os.path.exists(local_header_path):
            return {"error": "ë¡œì»¬ ë¹Œë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        # S3 ì—…ë¡œë“œ
        s3 = get_s3_client()
        
        # DLL íŒŒì¼ ì—…ë¡œë“œ
        with open(local_dll_path, 'rb') as f:
            library_content = f.read()
            
        s3.put_object(
            Bucket=S3_BUCKET_NAME,
            Key=f"{build_id}.{build_info['filename'].split('.')[-1]}",
            Body=library_content,
            ContentType='application/octet-stream'
        )
        
        # í—¤ë” íŒŒì¼ ì—…ë¡œë“œ
        with open(local_header_path, 'r', encoding='utf-8') as f:
            header_content = f.read()
            
        s3.put_object(
            Bucket=S3_BUCKET_NAME,
            Key=f"{build_id}.h",
            Body=header_content.encode('utf-8'),
            ContentType='text/plain'
        )
        
        # URL ìƒì„±
        file_extension = build_info['filename'].split('.')[-1]
        s3_url = f"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{build_id}.{file_extension}"
        header_url = f"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{build_id}.h"
        
        # DynamoDB ì—…ë°ì´íŠ¸ (ì—…ë¡œë“œ ì™„ë£Œ ìƒíƒœ)
        table.update_item(
            Key={'build_id': build_id},
            UpdateExpression='SET #status = :status, s3_url = :s3_url, header_url = :header_url, upload_comment = :comment, upload_timestamp = :upload_time',
            ExpressionAttributeNames={'#status': 'status'},
            ExpressionAttributeValues={
                ':status': 'uploaded',
                ':s3_url': s3_url,
                ':header_url': header_url,
                ':comment': comment,
                ':upload_time': datetime.now().isoformat()
            }
        )
        
        # ë¡œì»¬ íŒŒì¼ ì •ë¦¬
        try:
            os.remove(local_dll_path)
            os.remove(local_header_path)
            print(f"ğŸ—‘ï¸ ë¡œì»¬ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        except:
            pass
        
        print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {s3_url}")
        
        return {
            "build_id": build_id,
            "s3_url": s3_url,
            "header_url": header_url,
            "status": "uploaded",
            "message": "ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
    except Exception as e:
        print(f"âŒ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        return {"error": f"ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}

def generate_header_file(utilities, library_type):
    """í—¤ë” íŒŒì¼ ìƒì„±"""
    print(f"ğŸ”§ í—¤ë” ìƒì„± ì‹œì‘: {len(utilities)}ê°œ í•¨ìˆ˜")
    
    header_content = f"""#ifndef UTILITY_LIBRARY_H
#define UTILITY_LIBRARY_H

#ifdef __cplusplus
extern "C" {{
#endif

"""
    
    if library_type == "dll":
        header_content += """#ifdef BUILDING_DLL
#define LIBRARY_API __declspec(dllexport)
#else
#define LIBRARY_API __declspec(dllimport)
#endif

"""
    else:
        header_content += """#define LIBRARY_API

"""
    
    # ê° í•¨ìˆ˜ì˜ ì„ ì–¸ ì¶”ê°€
    for i, utility in enumerate(utilities):
        print(f"\n--- í—¤ë” ìƒì„± í•¨ìˆ˜ {i+1}: {utility.get('name', 'Unknown')} ---")
        
        purpose = utility.get('purpose', 'í•¨ìˆ˜')
        
        # AIê°€ ì œê³µí•œ header_declarationì„ ìš°ì„  ì‚¬ìš©
        if 'header_declaration' in utility and utility['header_declaration'].strip():
            header_declaration = utility['header_declaration']
            print(f"ğŸ”§ AI ì œê³µ í—¤ë” ì‚¬ìš©: {header_declaration}")
        else:
            # ì½”ë“œì—ì„œ í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ì¶”ì¶œ
            code = utility.get('code', '')
            func_name = utility.get('name', 'Unknown')
            
            # í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ì¶”ì¶œ (ì²« ë²ˆì§¸ ì¤„ì—ì„œ)
            lines = code.split('\n')
            signature_line = ""
            for line in lines:
                if func_name + '(' in line and not line.strip().startswith('//'):
                    signature_line = line.strip()
                    break
            
            if signature_line:
                # ì‹œê·¸ë‹ˆì²˜ì—ì„œ ì¤‘ê´„í˜¸ ì œê±°
                if '{' in signature_line:
                    signature_line = signature_line.split('{')[0].strip()
                
                # LIBRARY_APIê°€ ì—†ìœ¼ë©´ ì¶”ê°€
                if not signature_line.startswith('LIBRARY_API'):
                    header_declaration = f"LIBRARY_API {signature_line};"
                else:
                    header_declaration = f"{signature_line};"
                    
                print(f"ğŸ”§ ì½”ë“œì—ì„œ ì¶”ì¶œí•œ í—¤ë”: {header_declaration}")
            else:
                # ë°±ì—…: ìˆ˜ë™ìœ¼ë¡œ ìƒì„±
                parameters = utility.get('parameters', 'void')
                return_type = utility.get('return_type', 'void').split(' - ')[0].strip()
                header_declaration = f"LIBRARY_API {return_type} {func_name}({parameters});"
                print(f"âš ï¸ ìˆ˜ë™ í—¤ë” ìƒì„±: {header_declaration}")
        
        header_content += f"""// {purpose}
{header_declaration}

"""
    
    header_content += """#ifdef __cplusplus
}
#endif

#endif // UTILITY_LIBRARY_H
"""
    
    return header_content

@app.get("/builds")
async def get_builds():
    dynamodb = get_dynamodb_client()
    table = dynamodb.Table(DYNAMODB_TABLE_NAME)
    
    try:
        response = table.scan()
        builds = response['Items']
        
        # ê° ë¹Œë“œì— ë‹¤ìš´ë¡œë“œ ë° ë¬¸ì„œ ìƒì„± URL ì¶”ê°€
        for build in builds:
            build_id = build.get('build_id')
            if build_id:
                build['dll_download_url'] = f"/download/{build_id}"
                build['header_download_url'] = f"/download/{build_id}/header"
                build['generate_docs_url'] = f"/generate_docs/{build_id}"
        
        return {"builds": builds}
    except Exception as e:
        return {"builds": []}

@app.get("/download/{build_id}")
async def download_library(build_id: str):
    # DynamoDBì—ì„œ ë¹Œë“œ ì •ë³´ ì¡°íšŒí•˜ì—¬ íŒŒì¼ í™•ì¥ì í™•ì¸
    dynamodb = get_dynamodb_client()
    table = dynamodb.Table(DYNAMODB_TABLE_NAME)
    
    try:
        response = table.get_item(Key={'build_id': build_id})
        if 'Item' in response:
            filename = response['Item'].get('filename', f"{build_id}.dll")
            file_extension = filename.split('.')[-1]
            
            # ë¡œì»¬ íŒŒì¼ ìš°ì„  í™•ì¸
            local_dll_path = response['Item'].get('local_dll_path')
            if local_dll_path and os.path.exists(local_dll_path):
                print(f"ğŸ“ ë¡œì»¬ íŒŒì¼ ë‹¤ìš´ë¡œë“œ: {local_dll_path}")
                return FileResponse(local_dll_path, filename=filename)
        else:
            file_extension = "dll"  # ê¸°ë³¸ê°’
            filename = f"{build_id}.{file_extension}"
    except:
        file_extension = "dll"
        filename = f"{build_id}.{file_extension}"
    
    # S3ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    s3 = get_s3_client()
    
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{file_extension}') as tmp_file:
            s3.download_file(S3_BUCKET_NAME, filename, tmp_file.name)
            return FileResponse(tmp_file.name, filename=filename)
    except Exception as e:
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

@app.get("/download/{build_id}/header")
async def download_header(build_id: str):
    """í—¤ë” íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    # S3ì—ì„œ í—¤ë” íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    s3 = get_s3_client()
    
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.h') as tmp_file:
            s3.download_file(S3_BUCKET_NAME, f"{build_id}.h", tmp_file.name)
            return FileResponse(tmp_file.name, filename=f"{build_id}.h", media_type='text/plain')
    except Exception as e:
        raise HTTPException(status_code=404, detail="í—¤ë” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

@app.get("/generate_docs/{build_id}")
async def generate_docs_from_build(build_id: str):
    """ë¹Œë“œ íˆìŠ¤í† ë¦¬ì—ì„œ ë¬¸ì„œ ìƒì„±"""
    dynamodb = get_dynamodb_client()
    table = dynamodb.Table(DYNAMODB_TABLE_NAME)
    
    try:
        # DynamoDBì—ì„œ ë¹Œë“œ ì •ë³´ ì¡°íšŒ
        response = table.get_item(Key={'build_id': build_id})
        if 'Item' not in response:
            raise HTTPException(status_code=404, detail="ë¹Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        build_info = response['Item']
        utilities = build_info.get('utilities', [])
        
        if not utilities:
            raise HTTPException(status_code=400, detail="í•¨ìˆ˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ë¬¸ì„œ ìƒì„± AI í˜¸ì¶œ
        if agent_wrapper:
            try:
                documentation = await agent_wrapper.generate_documentation(utilities)
                
                # ë¬¸ì„œë¥¼ S3ì— ì—…ë¡œë“œ
                s3 = get_s3_client()
                doc_content = f"""# {build_info.get('comment', 'ìœ í‹¸ë¦¬í‹° ë¼ì´ë¸ŒëŸ¬ë¦¬')} ë¬¸ì„œ

{documentation}

---
ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ë¹Œë“œ ID: {build_id}
"""
                
                s3.put_object(
                    Bucket=S3_BUCKET_NAME,
                    Key=f"{build_id}_docs.md",
                    Body=doc_content.encode('utf-8'),
                    ContentType='text/markdown'
                )
                
                doc_url = f"https://{S3_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com/{build_id}_docs.md"
                
                # DynamoDBì— ë¬¸ì„œ URL ì—…ë°ì´íŠ¸
                table.update_item(
                    Key={'build_id': build_id},
                    UpdateExpression='SET doc_url = :doc_url',
                    ExpressionAttributeValues={':doc_url': doc_url}
                )
                
                return {
                    "success": True,
                    "doc_url": doc_url,
                    "message": "ë¬¸ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"
                }
                
            except Exception as e:
                print(f"ë¬¸ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
                raise HTTPException(status_code=500, detail=f"ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        else:
            raise HTTPException(status_code=503, detail="ë¬¸ì„œ ìƒì„± ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"ë¬¸ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@app.get("/extraction_history")
async def get_extraction_history():
    """ì¶”ì¶œ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    dynamodb = get_dynamodb_client()
    table = dynamodb.Table(DYNAMODB_TABLE_NAME)
    
    try:
        response = table.scan()
        builds = response['Items']
        
        # ëª¨ë“  ë¹Œë“œì—ì„œ ì¶”ì¶œëœ í•¨ìˆ˜ë“¤ ìˆ˜ì§‘
        all_functions = []
        for build in builds:
            utilities = build.get('utilities', [])
            for utility in utilities:
                function_data = {
                    'id': f"{build.get('build_id', '')}_{utility.get('name', '')}",
                    'build_id': build.get('build_id', ''),
                    'name': utility.get('name', ''),
                    'description': utility.get('description', ''),
                    'code': utility.get('code', ''),
                    'parameters': utility.get('parameters', ''),
                    'return_type': utility.get('return_type', ''),
                    'purpose': utility.get('purpose', ''),
                    'header_declaration': utility.get('header_declaration', ''),
                    'required_headers': utility.get('required_headers', []),
                    'timestamp': build.get('timestamp', ''),
                    'comment': build.get('comment', '')
                }
                all_functions.append(function_data)
        
        # ì‹œê°„ìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
        all_functions.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        
        return {"functions": all_functions}
    except Exception as e:
        print(f"ì¶”ì¶œ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return {"functions": []}

@app.post("/search_functions")
async def search_functions(request: dict):
    """í•¨ìˆ˜ ê²€ìƒ‰"""
    search_term = request.get('search_term', '').lower()
    
    # ì „ì²´ í•¨ìˆ˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    history_response = await get_extraction_history()
    all_functions = history_response.get('functions', [])
    
    if not search_term:
        return {"functions": all_functions}
    
    # ê²€ìƒ‰ í•„í„°ë§
    filtered_functions = []
    for func in all_functions:
        if (search_term in func.get('name', '').lower() or
            search_term in func.get('description', '').lower() or
            search_term in func.get('purpose', '').lower() or
            search_term in func.get('code', '').lower()):
            filtered_functions.append(func)
    
    return {"functions": filtered_functions}

@app.post("/add_function_to_extractor")
async def add_function_to_extractor(request: dict):
    """ì„ íƒëœ í•¨ìˆ˜ë¥¼ ìœ í‹¸ë¦¬í‹° ì¶”ì¶œê¸°ì— ì¶”ê°€"""
    try:
        function_data = request.get('function_data')
        if not function_data:
            raise HTTPException(status_code=400, detail="í•¨ìˆ˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # í•¨ìˆ˜ ì½”ë“œë¥¼ íŒŒì¼ í˜•íƒœë¡œ ë³€í™˜
        code_content = f"""// {function_data.get('description', 'í•¨ìˆ˜')}
{function_data.get('code', '')}
"""
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ë¶„ì„ ê°€ëŠ¥í•˜ê²Œ í•¨
        temp_filename = f"extracted_{function_data.get('name', 'function')}.cpp"
        
        return {
            "success": True,
            "code_content": code_content,
            "function_name": function_data.get('name', ''),
            "filename": temp_filename,
            "message": "í•¨ìˆ˜ê°€ ìœ í‹¸ë¦¬í‹° ì¶”ì¶œê¸°ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤"
        }
        
    except Exception as e:
        print(f"í•¨ìˆ˜ ì¶”ê°€ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="í•¨ìˆ˜ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

async def download_docs(build_id: str):
    """ë¬¸ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    s3 = get_s3_client()
    
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.md') as tmp_file:
            s3.download_file(S3_BUCKET_NAME, f"{build_id}_docs.md", tmp_file.name)
            return FileResponse(tmp_file.name, filename=f"{build_id}_docs.md", media_type='text/markdown')
    except Exception as e:
        raise HTTPException(status_code=404, detail="ë¬¸ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

@app.get("/index.html")
async def serve_index():
    """index.html ì§ì ‘ ì„œë¹™"""
    try:
        index_path = os.path.join(CURRENT_DIR, "index.html")
        with open(index_path, "r", encoding="utf-8") as f:
            content = f.read()
        return HTMLResponse(content=content)
    except Exception as e:
        return HTMLResponse(content="<h1>index.htmlì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤</h1>")

@app.get("/new")
async def new_interface():
    """ìƒˆë¡œìš´ ì¸í„°í˜ì´ìŠ¤ - ìºì‹œ ìš°íšŒìš©"""
    try:
        index_path = os.path.join(CURRENT_DIR, "index.html")
        with open(index_path, "r", encoding="utf-8") as f:
            content = f.read()
        return HTMLResponse(content=content)
    except Exception as e:
        return HTMLResponse(content="<h1>íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤</h1>")

@app.get("/")
async def read_root():
    """ë©”ì¸ í˜ì´ì§€ ì œê³µ"""
    try:
        index_path = os.path.join(CURRENT_DIR, "index.html")
        print(f"ğŸ” Loading index.html from: {index_path}")
        print(f"ğŸ” File exists: {os.path.exists(index_path)}")
        
        with open(index_path, "r", encoding="utf-8") as f:
            content = f.read()
        
        print(f"ğŸ” Content length: {len(content)}")
        print(f"ğŸ” Title in content: {'AI ê°œë°œ ë„êµ¬ í”Œë«í¼' in content}")
        
        return HTMLResponse(content=content)
    except Exception as e:
        print(f"âŒ Index.html ë¡œë“œ ì˜¤ë¥˜: {e}")
        return HTMLResponse(content="<h1>Index.htmlì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤</h1>")

@app.post("/analyze_commit_changes")
async def analyze_commit_changes(request: CommitAnalysisRequest):
    """ì»¤ë°‹ ë³€ê²½ì‚¬í•­ ë¶„ì„"""
    try:
        # ë ˆí¬ì§€í„°ë¦¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        repo_name = request.repo_id.replace('/', '_')
        repo_dir = os.path.join(LOCAL_REPOS_DIR, repo_name)
        
        if not os.path.exists(repo_dir):
            return {"error": "ë ˆí¬ì§€í„°ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë ˆí¬ì§€í„°ë¦¬ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."}
        
        # Git ë ˆí¬ì§€í„°ë¦¬ ê°ì²´ ìƒì„±
        repo = git.Repo(repo_dir)
        
        # ì»¤ë°‹ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
        try:
            commit = repo.commit(request.commit_sha)
        except Exception as e:
            return {"error": f"ì»¤ë°‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"}
        
        # ì»¤ë°‹ì˜ ë³€ê²½ì‚¬í•­ ë¶„ì„
        files_data = []
        total_additions = 0
        total_deletions = 0
        difficulty_scores = []
        
        # ë¶€ëª¨ ì»¤ë°‹ê³¼ ë¹„êµí•˜ì—¬ ë³€ê²½ì‚¬í•­ ì¶”ì¶œ
        if commit.parents:
            parent_commit = commit.parents[0]
            diff = parent_commit.diff(commit, create_patch=True)
            
            for diff_item in diff:
                file_path = diff_item.a_path or diff_item.b_path
                if not file_path:
                    continue
                    
                file_ext = os.path.splitext(file_path)[1].lower()
                supported_extensions = {'.py', '.js', '.ts', '.java', '.cpp', '.c', '.cs', '.php', '.rb', '.go'}
                if file_ext not in supported_extensions:
                    continue
                
                try:
                    # Git statsë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ë³€ê²½ì‚¬í•­ í†µê³„ ê°€ì ¸ì˜¤ê¸°
                    stats = commit.stats.files.get(file_path, {'insertions': 0, 'deletions': 0})
                    added_lines = stats.get('insertions', 0)
                    deleted_lines = stats.get('deletions', 0)
                    
                    # diffê°€ ì—†ìœ¼ë©´ patchì—ì„œ ì§ì ‘ ê³„ì‚°
                    if added_lines == 0 and deleted_lines == 0 and diff_item.diff:
                        try:
                            diff_text = diff_item.diff.decode('utf-8', errors='ignore')
                            for line in diff_text.split('\n'):
                                if line.startswith('+') and not line.startswith('+++'):
                                    added_lines += 1
                                elif line.startswith('-') and not line.startswith('---'):
                                    deleted_lines += 1
                        except:
                            pass
                    
                    # í˜„ì¬ íŒŒì¼ ë‚´ìš© ë¶„ì„
                    current_content = ""
                    current_file_path = os.path.join(repo_dir, file_path)
                    if os.path.exists(current_file_path):
                        with open(current_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            current_content = f.read()
                    elif diff_item.b_blob:  # ìƒˆ íŒŒì¼ì¸ ê²½ìš°
                        current_content = diff_item.b_blob.data_stream.read().decode('utf-8', errors='ignore')
                    
                    if current_content or added_lines > 0:
                        file_analysis = analyze_commit_file_changes(
                            file_path, current_content, added_lines, deleted_lines
                        )
                        
                        if file_analysis:
                            files_data.append(file_analysis)
                            total_additions += added_lines
                            total_deletions += deleted_lines
                            difficulty_scores.append(file_analysis['difficulty_score'])
                
                except Exception as e:
                    print(f"íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜ {file_path}: {e}")
                    continue
        
        # ìš”ì•½ ì •ë³´ ê³„ì‚°
        summary = {
            'total_files': len(files_data),
            'total_additions': total_additions,
            'total_deletions': total_deletions,
            'avg_difficulty': round(sum(difficulty_scores) / len(difficulty_scores), 2) if difficulty_scores else 0
        }
        
        return {
            'summary': summary,
            'files': files_data,
            'commit_info': {
                'sha': request.commit_sha,
                'message': commit.message,
                'author': commit.author.name,
                'date': commit.committed_datetime.isoformat(),
                'branch': request.branch_name
            }
        }
        
    except Exception as e:
        return {"error": f"ì»¤ë°‹ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

def analyze_commit_file_changes(file_path, content, added_lines, deleted_lines):
    """ì»¤ë°‹ì—ì„œ ë³€ê²½ëœ íŒŒì¼ ë¶„ì„"""
    try:
        lines = content.split('\n')
        total_lines = len(lines)
        
        # ì½”ë“œ ë¼ì¸ê³¼ ì£¼ì„ ë¼ì¸ êµ¬ë¶„
        code_lines = 0
        comment_lines = 0
        
        for line in lines:
            stripped = line.strip()
            if not stripped:
                continue
            elif stripped.startswith('#') or stripped.startswith('//') or stripped.startswith('/*') or stripped.startswith('*'):
                comment_lines += 1
            else:
                code_lines += 1
        
        # ì¶”ê°€/ì‚­ì œëœ ë¼ì¸ì—ì„œ ì½”ë“œì™€ ì£¼ì„ êµ¬ë¶„ (ê°„ë‹¨í•œ ì¶”ì •)
        code_lines_added = max(0, int(added_lines * 0.8))  # 80%ê°€ ì½”ë“œë¼ê³  ê°€ì •
        comment_lines_added = added_lines - code_lines_added
        code_lines_deleted = max(0, int(deleted_lines * 0.8))
        comment_lines_deleted = deleted_lines - code_lines_deleted
        
        # ë³€ê²½ì‚¬í•­ ê¸°ë°˜ ë‚œì´ë„ ê³„ì‚°
        change_complexity = added_lines + deleted_lines
        file_complexity = calculate_complexity(content)
        
        # ë‚œì´ë„ ì ìˆ˜ (1-10)
        difficulty = min(10, max(1, 
            (change_complexity // 10) +  # ë³€ê²½ëŸ‰ ê¸°ë°˜
            (file_complexity // 20) +    # íŒŒì¼ ë³µì¡ë„ ê¸°ë°˜
            (1 if added_lines > deleted_lines else 0)  # ì¶”ê°€ê°€ ë” ë§ìœ¼ë©´ +1
        ))
        
        # ê°œë°œì ìˆ˜ì¤€ ì¶”ì •
        dev_level = get_developer_level(difficulty)
        
        # íŒŒì¼ ê²½ë¡œ ì •ë¦¬
        clean_path = file_path.replace('\\', '/')
        if clean_path.startswith('server/local_storage/repositories/'):
            path_parts = clean_path.split('/')
            if len(path_parts) > 4:
                clean_path = '/'.join(path_parts[4:])
        elif 'local_storage/repositories/' in clean_path:
            parts = clean_path.split('local_storage/repositories/')
            if len(parts) > 1:
                remaining = parts[1].split('/', 1)
                if len(remaining) > 1:
                    clean_path = remaining[1]
        
        return {
            'file_path': clean_path,
            'code_lines': code_lines,
            'code_lines_added': code_lines_added,
            'code_lines_deleted': code_lines_deleted,
            'comment_lines': comment_lines,
            'comment_lines_added': comment_lines_added,
            'comment_lines_deleted': comment_lines_deleted,
            'difficulty_score': difficulty,
            'developer_level': dev_level,
            'total_additions': added_lines,
            'total_deletions': deleted_lines
        }
        
    except Exception as e:
        print(f"ì»¤ë°‹ íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None

@app.post("/get_file_content")
async def get_file_content(request: FileContentRequest):
    """íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
    try:
        file_path = request.file_path
        print(f"ğŸ“ íŒŒì¼ ë‚´ìš© ìš”ì²­: {file_path}, repo_id: {request.repo_id}")
        
        # íŒŒì¼ ê²½ë¡œê°€ ì´ë¯¸ ì ˆëŒ€ ê²½ë¡œì¸ì§€ í™•ì¸
        if os.path.isabs(file_path) and os.path.exists(file_path):
            full_path = file_path
            print(f"ğŸ“‚ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©: {full_path}")
        elif request.repo_id:
            if request.repo_id.startswith('upload_'):
                # ì—…ë¡œë“œëœ íŒŒì¼
                upload_dir = os.path.join(LOCAL_REPOS_DIR, request.repo_id)
                normalized_path = file_path.replace('/', os.sep).replace('\\', os.sep)
                full_path = os.path.join(upload_dir, normalized_path)
                print(f"ğŸ“‚ ì—…ë¡œë“œ íŒŒì¼ ê²½ë¡œ: {full_path}")
            else:
                # GitHub ë ˆí¬ì§€í„°ë¦¬
                repo_name = request.repo_id.replace('/', '_')
                repo_dir = os.path.join(LOCAL_REPOS_DIR, repo_name)
                normalized_path = file_path.replace('/', os.sep).replace('\\', os.sep)
                full_path = os.path.join(repo_dir, normalized_path)
                print(f"ğŸ“‚ ë ˆí¬ì§€í„°ë¦¬ íŒŒì¼ ê²½ë¡œ: {full_path}")
        else:
            # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
            full_path = os.path.abspath(file_path)
            print(f"ğŸ“‚ ë³€í™˜ëœ ì ˆëŒ€ ê²½ë¡œ: {full_path}")
        
        print(f"ğŸ” íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(full_path)}")
        if not os.path.exists(full_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {full_path}")
            return {"error": f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {full_path}"}
        
        # íŒŒì¼ í¬ê¸° ì²´í¬ (10MB ì œí•œ)
        file_size = os.path.getsize(full_path)
        print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size} bytes")
        if file_size > 10 * 1024 * 1024:  # 10MB
            return {"error": "íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. (10MB ì œí•œ)"}
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
            print(f"âœ… UTF-8ë¡œ íŒŒì¼ ì½ê¸° ì„±ê³µ, ê¸¸ì´: {len(content)}")
        except UnicodeDecodeError:
            try:
                with open(full_path, 'r', encoding='cp949') as f:
                    content = f.read()
                print(f"âœ… CP949ë¡œ íŒŒì¼ ì½ê¸° ì„±ê³µ, ê¸¸ì´: {len(content)}")
            except UnicodeDecodeError:
                with open(full_path, 'r', encoding='latin-1') as f:
                    content = f.read()
                print(f"âœ… Latin-1ë¡œ íŒŒì¼ ì½ê¸° ì„±ê³µ, ê¸¸ì´: {len(content)}")
        
        # HTML ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        import html
        escaped_content = html.escape(content)
        print(f"âœ… HTML ì´ìŠ¤ì¼€ì´í”„ ì™„ë£Œ, ìµœì¢… ê¸¸ì´: {len(escaped_content)}")
        
        return {
            "content": escaped_content,
            "file_size": file_size,
            "encoding": "utf-8"
        }
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
        return {"error": f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}"}

@app.post("/get_commit_file_diff")
async def get_commit_file_diff(request: CommitFileDiffRequest):
    """ì»¤ë°‹ì—ì„œ íŒŒì¼ì˜ ë³€ê²½ ì „/í›„ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
    try:
        print(f"ğŸ“ ì»¤ë°‹ íŒŒì¼ diff ìš”ì²­: {request.file_path}, repo_id: {request.repo_id}, commit: {request.commit_sha}")
        
        if not request.repo_id or not request.commit_sha:
            return {"error": "repo_idì™€ commit_shaê°€ í•„ìš”í•©ë‹ˆë‹¤."}
        
        # ë ˆí¬ì§€í„°ë¦¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        repo_name = request.repo_id.replace('/', '_')
        repo_dir = os.path.join(LOCAL_REPOS_DIR, repo_name)
        
        if not os.path.exists(repo_dir):
            return {"error": "ë ˆí¬ì§€í„°ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        # Git ë ˆí¬ì§€í„°ë¦¬ ê°ì²´ ìƒì„±
        repo = git.Repo(repo_dir)
        
        try:
            commit = repo.commit(request.commit_sha)
        except Exception as e:
            return {"error": f"ì»¤ë°‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"}
        
        # íŒŒì¼ ê²½ë¡œ ì •ê·œí™”
        file_path = request.file_path.replace('\\', '/')
        
        before_content = ""
        after_content = ""
        
        try:
            # ë³€ê²½ í›„ ë‚´ìš© (í˜„ì¬ ì»¤ë°‹)
            try:
                after_blob = commit.tree[file_path]
                after_content = after_blob.data_stream.read().decode('utf-8', errors='ignore')
            except KeyError:
                # íŒŒì¼ì´ ì‚­ì œëœ ê²½ìš°
                after_content = "[íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤]"
            
            # ë³€ê²½ ì „ ë‚´ìš© (ë¶€ëª¨ ì»¤ë°‹)
            if commit.parents:
                parent_commit = commit.parents[0]
                try:
                    before_blob = parent_commit.tree[file_path]
                    before_content = before_blob.data_stream.read().decode('utf-8', errors='ignore')
                except KeyError:
                    # ìƒˆë¡œ ìƒì„±ëœ íŒŒì¼ì¸ ê²½ìš°
                    before_content = "[ìƒˆë¡œ ìƒì„±ëœ íŒŒì¼ì…ë‹ˆë‹¤]"
            else:
                # ì²« ë²ˆì§¸ ì»¤ë°‹ì¸ ê²½ìš°
                before_content = "[ì²« ë²ˆì§¸ ì»¤ë°‹ì…ë‹ˆë‹¤]"
            
            # HTML ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
            import html
            before_content = html.escape(before_content)
            after_content = html.escape(after_content)
            
            return {
                "before_content": before_content,
                "after_content": after_content,
                "file_path": file_path,
                "commit_sha": request.commit_sha
            }
            
        except Exception as e:
            return {"error": f"íŒŒì¼ diff ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"}
        
    except Exception as e:
        print(f"âŒ ì»¤ë°‹ íŒŒì¼ diff ì˜¤ë¥˜: {str(e)}")
        return {"error": f"ì»¤ë°‹ íŒŒì¼ diff ì‹¤íŒ¨: {str(e)}"}

@app.post("/submit_feedback")
async def submit_feedback(request: FeedbackRequest):
    """ì‚¬ìš©ì í”¼ë“œë°± ì²˜ë¦¬"""
    try:
        # í”¼ë“œë°± ë°ì´í„° ì¤€ë¹„
        feedback_data = {
            'file_name': request.file_name,
            'ai_difficulty': request.ai_difficulty,
            'user_difficulty': request.user_difficulty,
            'difficulty_diff': request.user_difficulty - request.ai_difficulty,
            'feedback_reason': request.feedback_reason,
            'file_content': request.file_content,
            'file_metrics': {
                'total_lines': request.file_data.get('total_lines', 0),
                'code_lines': request.file_data.get('code_lines', 0),
                'complexity': request.file_data.get('cyclomatic_complexity', 0),
                'language': request.file_data.get('language', 'Unknown')
            },
            'timestamp': datetime.now().isoformat()
        }
        
        # í”¼ë“œë°± ë¡œì»¬ ì €ì¥
        feedback_file = os.path.join(CURRENT_DIR, 'local_storage', 'feedback.json')
        feedbacks = []
        if os.path.exists(feedback_file):
            with open(feedback_file, 'r', encoding='utf-8') as f:
                feedbacks = json.load(f)
        
        feedbacks.append(feedback_data)
        
        os.makedirs(os.path.dirname(feedback_file), exist_ok=True)
        with open(feedback_file, 'w', encoding='utf-8') as f:
            json.dump(feedbacks, f, ensure_ascii=False, indent=2)
        
        # ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±
        difficulty_diff = feedback_data['difficulty_diff']
        if difficulty_diff > 0:
            message = f"ì‚¬ìš©ìê°€ AIë³´ë‹¤ {difficulty_diff}ì  ë” ì–´ë µë‹¤ê³  í‰ê°€í–ˆìŠµë‹ˆë‹¤. í–¥í›„ ìœ ì‚¬í•œ ì½”ë“œ íŒ¨í„´ì— ëŒ€í•´ ë‚œì´ë„ë¥¼ ìƒí–¥ ì¡°ì •í•˜ê² ìŠµë‹ˆë‹¤."
        elif difficulty_diff < 0:
            message = f"ì‚¬ìš©ìê°€ AIë³´ë‹¤ {abs(difficulty_diff)}ì  ë” ì‰½ë‹¤ê³  í‰ê°€í–ˆìŠµë‹ˆë‹¤. í•´ë‹¹ ì½”ë“œ ìœ í˜•ì˜ ë‚œì´ë„ í‰ê°€ ê¸°ì¤€ì„ ì™„í™”í•˜ê² ìŠµë‹ˆë‹¤."
        else:
            message = "ì‚¬ìš©ìì™€ AI í‰ê°€ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤. í˜„ì¬ í‰ê°€ ê¸°ì¤€ì´ ì ì ˆí•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤."
        
        return {
            'success': True,
            'message': 'í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'llm_response': {'status': 'processed', 'message': message}
        }
        
    except Exception as e:
        return {'error': f'í”¼ë“œë°± ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}'}

@app.post("/submit_commit_feedback")
async def submit_commit_feedback(request: dict):
    """ì»¤ë°‹ ë³€ê²½ì‚¬í•­ í”¼ë“œë°± ì²˜ë¦¬"""
    try:
        feedback_data = {
            'file_name': request.get('file_name'),
            'file_path': request.get('file_path'),
            'repo_id': request.get('repo_id'),
            'commit_sha': request.get('commit_sha'),
            'ai_difficulty': request.get('ai_difficulty'),
            'user_difficulty': request.get('user_difficulty'),
            'difficulty_diff': request.get('user_difficulty', 0) - request.get('ai_difficulty', 0),
            'feedback_reason': request.get('feedback_reason'),
            'timestamp': datetime.now().isoformat()
        }
        
        # í”¼ë“œë°± ë¡œì»¬ ì €ì¥
        feedback_file = os.path.join(CURRENT_DIR, 'local_storage', 'commit_feedback.json')
        feedbacks = []
        if os.path.exists(feedback_file):
            with open(feedback_file, 'r', encoding='utf-8') as f:
                feedbacks = json.load(f)
        
        feedbacks.append(feedback_data)
        
        os.makedirs(os.path.dirname(feedback_file), exist_ok=True)
        with open(feedback_file, 'w', encoding='utf-8') as f:
            json.dump(feedbacks, f, ensure_ascii=False, indent=2)
        
        # ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±
        difficulty_diff = feedback_data['difficulty_diff']
        if difficulty_diff > 0:
            message = f"ì»¤ë°‹ ë³€ê²½ì‚¬í•­ì´ AI ì˜ˆìƒë³´ë‹¤ {difficulty_diff}ì  ë” ì–´ë ¤ì› ë‹¤ê³  í‰ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. í–¥í›„ ìœ ì‚¬í•œ ë³€ê²½ íŒ¨í„´ì— ëŒ€í•´ ë‚œì´ë„ë¥¼ ìƒí–¥ ì¡°ì •í•˜ê² ìŠµë‹ˆë‹¤."
        elif difficulty_diff < 0:
            message = f"ì»¤ë°‹ ë³€ê²½ì‚¬í•­ì´ AI ì˜ˆìƒë³´ë‹¤ {abs(difficulty_diff)}ì  ë” ì‰¬ì› ë‹¤ê³  í‰ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. í•´ë‹¹ ë³€ê²½ ìœ í˜•ì˜ ë‚œì´ë„ í‰ê°€ ê¸°ì¤€ì„ ì™„í™”í•˜ê² ìŠµë‹ˆë‹¤."
        else:
            message = "ì»¤ë°‹ ë³€ê²½ì‚¬í•­ì— ëŒ€í•œ ì‚¬ìš©ìì™€ AI í‰ê°€ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤. í˜„ì¬ í‰ê°€ ê¸°ì¤€ì´ ì ì ˆí•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤."
        
        return {
            'success': True,
            'message': 'ì»¤ë°‹ í”¼ë“œë°±ì´ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'llm_response': {'status': 'processed', 'message': message}
        }
        
    except Exception as e:
        return {'error': f'ì»¤ë°‹ í”¼ë“œë°± ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}'}

@app.get("/advanced_utility_extractor.html")
async def serve_utility_extractor():
    """ìœ í‹¸ë¦¬í‹° ì¶”ì¶œê¸° í˜ì´ì§€ ì œê³µ"""
    return FileResponse(os.path.join(CURRENT_DIR, "advanced_utility_extractor.html"))

@app.get("/project_evaluation.html")
async def serve_project_evaluation():
    """í”„ë¡œì íŠ¸ í‰ê°€ í˜ì´ì§€ ì œê³µ"""
    return FileResponse(os.path.join(CURRENT_DIR, "project_evaluation.html"))

@app.get("/project_analyzer.html")
async def serve_project_analyzer():
    """í”„ë¡œì íŠ¸ ë¶„ì„ê¸° í˜ì´ì§€ ì œê³µ"""
    return FileResponse(os.path.join(CURRENT_DIR, "project_analyzer.html"))

@app.get("/github_analyzer.html")
async def serve_github_analyzer():
    """GitHub ë¶„ì„ê¸° í˜ì´ì§€ ì œê³µ"""
    return FileResponse(os.path.join(CURRENT_DIR, "github_analyzer.html"))

# GitHub API í”„ë¡ì‹œ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/github/{path:path}")
async def github_proxy(path: str):
    """GitHub API í”„ë¡ì‹œ (CORS í•´ê²°)"""
    import httpx
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"https://api.github.com/{path}")
            return JSONResponse(
                content=response.json(),
                headers={"Access-Control-Allow-Origin": "*"}
            )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/github/repos/{owner}/{repo}")
async def get_github_repo(owner: str, repo: str):
    """GitHub ì €ì¥ì†Œ ì •ë³´ ì¡°íšŒ"""
    import httpx
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"https://api.github.com/repos/{owner}/{repo}")
            return response.json()
    except Exception as e:
        return {"error": str(e)}

@app.get("/api/github/repos/{owner}/{repo}/branches")
async def get_github_branches(owner: str, repo: str):
    """GitHub ì €ì¥ì†Œ ë¸Œëœì¹˜ ëª©ë¡ ì¡°íšŒ"""
    import httpx
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"https://api.github.com/repos/{owner}/{repo}/branches")
            return response.json()
    except Exception as e:
        return [{"name": "main", "commit": {"sha": "abc123"}}]

@app.get("/api/github/repos/{owner}/{repo}/commits")
async def get_github_commits(owner: str, repo: str, per_page: int = 50):
    """GitHub ì €ì¥ì†Œ ì»¤ë°‹ ëª©ë¡ ì¡°íšŒ"""
    import httpx
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"https://api.github.com/repos/{owner}/{repo}/commits?per_page={per_page}")
            return response.json()
    except Exception as e:
        return [{"sha": "abc123", "commit": {"message": "Initial commit"}}]



def force_remove_readonly(func, path, exc):
    """ì½ê¸° ì „ìš© íŒŒì¼ ê°•ì œ ì‚­ì œ"""
    import stat
    try:
        os.chmod(path, stat.S_IWRITE)
        func(path)
    except Exception:
        pass

@app.post("/analyze_github_repo")
async def analyze_github_repo(request: GitRepoRequest):
    """GitHub ë ˆí¬ì§€í„°ë¦¬ í´ë¡  ë° ë¶„ì„"""
    try:
        # ì˜êµ¬ ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        repo_name = request.repo_id.replace('/', '_')
        repo_dir = os.path.join(LOCAL_REPOS_DIR, repo_name)
        
        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê°•ì œ ì‚­ì œ í›„ ì¬í´ë¡ 
        if os.path.exists(repo_dir):
            try:
                import shutil
                shutil.rmtree(repo_dir, onerror=force_remove_readonly)
            except Exception as e:
                print(f"ê¸°ì¡´ í´ë” ì‚­ì œ ì‹¤íŒ¨: {e}")
        
        # Git í´ë¡ 
        try:
            print(f"ğŸ“¥ í´ë¡  ì¤‘: {request.repo_url} -> {repo_dir}")
            import git
            git.Repo.clone_from(request.repo_url, repo_dir)
            print(f"âœ… í´ë¡  ì™„ë£Œ: {repo_dir}")
        except Exception as e:
            return {"error": f"ë ˆí¬ì§€í„°ë¦¬ í´ë¡  ì‹¤íŒ¨: {str(e)}"}
        
        # í”„ë¡œì íŠ¸ ë¶„ì„
        return analyze_project_directory(repo_dir)
            
    except Exception as e:
        return {"error": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

@app.get("/download/{build_id}/docs")
async def download_docs(build_id: str):
    """ë¬¸ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    s3 = get_s3_client()
    
    try:
        # S3ì—ì„œ ë¬¸ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        response = s3.get_object(Bucket=S3_BUCKET_NAME, Key=f"{build_id}_docs.md")
        content = response['Body'].read()
        
        return Response(
            content=content,
            media_type='text/markdown',
            headers={
                'Content-Disposition': f'attachment; filename="{build_id}_docs.md"'
            }
        )
    except Exception as e:
        print(f"ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=404, detail="ë¬¸ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

@app.post("/analyze_project")
async def analyze_project(files: List[UploadFile] = File(...)):
    """ì—…ë¡œë“œëœ íŒŒì¼ë“¤ ë¶„ì„"""
    try:
        # ì˜êµ¬ ì €ì¥ì†Œì— íŒŒì¼ë“¤ ì €ì¥
        upload_id = str(uuid.uuid4())
        upload_dir = os.path.join(LOCAL_REPOS_DIR, f"upload_{upload_id}")
        os.makedirs(upload_dir, exist_ok=True)
        
        print(f"ğŸ“ ì—…ë¡œë“œ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬: {upload_dir}")
        
        for file in files:
            file_path = os.path.join(upload_dir, file.filename)
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            content = await file.read()
            with open(file_path, 'wb') as f:
                f.write(content)
            print(f"ğŸ“„ íŒŒì¼ ì €ì¥: {file.filename}")
        
        # í”„ë¡œì íŠ¸ ë¶„ì„
        result = analyze_project_directory(upload_dir)
        
        # ê²°ê³¼ì— upload_id ì¶”ê°€
        result['upload_id'] = upload_id
        return result
            
    except Exception as e:
        return {"error": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

def analyze_project_directory(project_dir):
    """í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ë¶„ì„"""
    extractor = FunctionExtractor()
    files_data = []
    total_lines = 0
    total_files = 0
    complexity_scores = []
    difficulty_scores = []
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ì
    supported_extensions = {'.py', '.js', '.ts', '.java', '.cpp', '.c', '.cs', '.php', '.rb', '.go'}
    
    for root, dirs, files in os.walk(project_dir):
        # ë¶ˆí•„ìš”í•œ ë””ë ‰í† ë¦¬ ì œì™¸
        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'build', 'dist']]
        
        for file in files:
            file_path = os.path.join(root, file)
            file_ext = os.path.splitext(file)[1].lower()
            
            if file_ext in supported_extensions:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # íŒŒì¼ ë¶„ì„
                    file_analysis = analyze_file(file_path, content, extractor)
                    if file_analysis:
                        files_data.append(file_analysis)
                        total_lines += file_analysis['total_lines']
                        total_files += 1
                        complexity_scores.append(file_analysis['cyclomatic_complexity'])
                        difficulty_scores.append(file_analysis['difficulty_score'])
                        
                except Exception as e:
                    print(f"íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜ {file_path}: {e}")
                    continue
    
    # ìš”ì•½ ì •ë³´ ê³„ì‚°
    summary = {
        'total_files': total_files,
        'total_lines': total_lines,
        'avg_complexity': round(sum(complexity_scores) / len(complexity_scores), 2) if complexity_scores else 0,
        'max_difficulty': max(difficulty_scores) if difficulty_scores else 0,
        'total_estimated_hours': sum(f['estimated_dev_hours'] for f in files_data)
    }
    
    return {
        'summary': summary,
        'files': files_data
    }

def analyze_file(file_path, content, extractor):
    """ê°œë³„ íŒŒì¼ ë¶„ì„"""
    try:
        lines = content.split('\n')
        total_lines = len(lines)
        code_lines = len([line for line in lines if line.strip() and not line.strip().startswith('#') and not line.strip().startswith('//')])
        comment_lines = total_lines - code_lines
        comment_ratio = f"{round((comment_lines / total_lines) * 100, 1)}%" if total_lines > 0 else "0%"
        
        # ë³µì¡ë„ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        complexity = calculate_complexity(content)
        
        # ê¸°ìˆ  ìŠ¤íƒ ê°ì§€
        tech_stack = detect_tech_stack(file_path, content)
        
        # ë‚œì´ë„ ì ìˆ˜ (1-10)
        difficulty = min(10, max(1, complexity // 5 + len(tech_stack)))
        
        # ê°œë°œì ìˆ˜ì¤€ ì¶”ì •
        dev_level = get_developer_level(difficulty)
        
        # ì˜ˆìƒ ê°œë°œ ì‹œê°„ (ì‹œê°„)
        estimated_hours = max(1, (code_lines // 50) + (complexity // 10))
        
        # íŒŒì¼ ê²½ë¡œ ì •ê·œí™”
        relative_path = os.path.relpath(file_path)
        # local_storage/repositories/í”„ë¡œì íŠ¸ëª…/ ë¶€ë¶„ ì œê±°
        path_parts = relative_path.replace('\\', '/').split('/')
        if len(path_parts) > 3 and 'local_storage' in path_parts and 'repositories' in path_parts:
            # repositories ë‹¤ìŒ í”„ë¡œì íŠ¸ëª… ì œê±°í•˜ê³  ê·¸ ì´í›„ ê²½ë¡œë§Œ ì‚¬ìš©
            repo_index = path_parts.index('repositories')
            if repo_index + 2 < len(path_parts):
                clean_path = '/'.join(path_parts[repo_index + 2:])
            else:
                clean_path = relative_path
        else:
            clean_path = relative_path
        
        return {
            'file_path': clean_path,
            'original_file_path': file_path,
            'total_lines': total_lines,
            'code_lines': code_lines,
            'code_comment_ratio': comment_ratio,
            'cyclomatic_complexity': complexity,
            'maintainability_index': max(0, min(100, 100 - complexity)),
            'estimated_dev_hours': estimated_hours,
            'difficulty_score': difficulty,
            'developer_level': dev_level,
            'pattern_score': min(10, max(1, 8 - (complexity // 10))),
            'optimization_score': min(10, max(1, 7 + (comment_lines // 10))),
            'best_practices_score': min(10, max(1, 6 + len(tech_stack))),
            'tech_stack': tech_stack,
            'language': tech_stack[0] if tech_stack else 'Unknown'
        }
    except Exception as e:
        print(f"íŒŒì¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None

def calculate_complexity(content):
    """ì½”ë“œ ë³µì¡ë„ ê³„ì‚°"""
    complexity = 1  # ê¸°ë³¸ ë³µì¡ë„
    
    # ì œì–´ êµ¬ì¡° ì¹´ìš´íŠ¸
    control_keywords = ['if', 'else', 'elif', 'for', 'while', 'switch', 'case', 'try', 'catch', 'except']
    for keyword in control_keywords:
        complexity += content.lower().count(keyword)
    
    # í•¨ìˆ˜/ë©”ì„œë“œ ì¹´ìš´íŠ¸
    complexity += content.count('def ') + content.count('function ') + content.count('public ') + content.count('private ')
    
    return min(100, complexity)

def detect_tech_stack(file_path, content):
    """ê¸°ìˆ  ìŠ¤íƒ ê°ì§€"""
    tech_stack = []
    file_ext = os.path.splitext(file_path)[1].lower()
    
    # íŒŒì¼ í™•ì¥ì ê¸°ë°˜
    ext_mapping = {
        '.py': 'Python',
        '.js': 'JavaScript',
        '.ts': 'TypeScript',
        '.java': 'Java',
        '.cpp': 'C++',
        '.c': 'C',
        '.cs': 'C#',
        '.php': 'PHP',
        '.rb': 'Ruby',
        '.go': 'Go'
    }
    
    if file_ext in ext_mapping:
        tech_stack.append(ext_mapping[file_ext])
    
    # í”„ë ˆì„ì›Œí¬/ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°ì§€
    frameworks = {
        'react': 'React',
        'vue': 'Vue.js',
        'angular': 'Angular',
        'django': 'Django',
        'flask': 'Flask',
        'spring': 'Spring',
        'express': 'Express.js',
        'jquery': 'jQuery'
    }
    
    content_lower = content.lower()
    for keyword, framework in frameworks.items():
        if keyword in content_lower:
            tech_stack.append(framework)
    
    return list(set(tech_stack))  # ì¤‘ë³µ ì œê±°

def get_developer_level(difficulty):
    """ë‚œì´ë„ ê¸°ë°˜ ê°œë°œì ìˆ˜ì¤€ ì¶”ì •"""
    if difficulty <= 3:
        return "ì´ˆê¸‰"
    elif difficulty <= 6:
        return "ì¤‘ê¸‰"
    elif difficulty <= 8:
        return "ê³ ê¸‰"
    else:
        return "ì „ë¬¸ê°€"

@app.post('/upload_to_history')
async def upload_to_history(request: dict):
    """ë¹Œë“œ íˆìŠ¤í† ë¦¬ì— ì—…ë¡œë“œ"""
    try:
        build_id = request.get('build_id')
        comment = request.get('comment', '')
        selected_utilities = request.get('selected_utilities', [])
        
        # DynamoDB í…Œì´ë¸” ì—°ê²°
        dynamodb = get_dynamodb_client()
        table = dynamodb.Table(DYNAMODB_TABLE_NAME)
        
        # DynamoDBì— íˆìŠ¤í† ë¦¬ ì €ì¥
        history_item = {
            'build_id': build_id,  # Primary key
            'id': build_id,        # Alternative key for compatibility
            'timestamp': datetime.now().isoformat(),
            'comment': comment,
            'utilities': selected_utilities,
            'utility_count': len(selected_utilities)
        }
        
        table.put_item(Item=history_item)
        
        return JSONResponse({
            'success': True,
            'message': 'ë¹Œë“œ íˆìŠ¤í† ë¦¬ì— ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!'
        })
        
    except Exception as e:
        print(f"íˆìŠ¤í† ë¦¬ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        return JSONResponse({'error': str(e)}, status_code=500)

@app.get('/get_history')
async def get_history():
    """ë¹Œë“œ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    try:
        # DynamoDB í…Œì´ë¸” ì—°ê²°
        dynamodb = get_dynamodb_client()
        table = dynamodb.Table(DYNAMODB_TABLE_NAME)
        
        response = table.scan()
        items = response.get('Items', [])
        
        # Decimal íƒ€ì…ì„ ì¼ë°˜ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        def convert_decimals(obj):
            if isinstance(obj, list):
                return [convert_decimals(item) for item in obj]
            elif isinstance(obj, dict):
                return {key: convert_decimals(value) for key, value in obj.items()}
            elif isinstance(obj, Decimal):
                return int(obj) if obj % 1 == 0 else float(obj)
            return obj
        
        items = convert_decimals(items)
        
        # ì‹œê°„ìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
        items.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        
        return JSONResponse({
            'success': True,
            'history': items
        })
        
    except Exception as e:
        print(f"íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return JSONResponse({'error': str(e)}, status_code=500)

from agents.doc_generator_agent import DocumentationAgent

# ì „ì—­ ë¬¸ì„œ ìƒì„± ì—ì´ì „íŠ¸
doc_agent = None

@app.on_event("startup")
async def startup_event():
    global doc_agent
    try:
        doc_agent = DocumentationAgent()
        print("âœ… ë¬¸ì„œ ìƒì„± AI ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ìƒì„± AI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

@app.get("/docs/{build_id}")
async def download_docs(build_id: str):
    """AI ê¸°ë°˜ ë¬¸ì„œ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ"""
    try:
        # DynamoDBì—ì„œ ë¹Œë“œ ì •ë³´ ì¡°íšŒ (ë‘ ê°€ì§€ í‚¤ë¡œ ì‹œë„)
        dynamodb = get_dynamodb_client()
        table = dynamodb.Table(DYNAMODB_TABLE_NAME)
        
        # ë¨¼ì € build_idë¡œ ì¡°íšŒ
        response = table.get_item(Key={'build_id': build_id})
        
        if 'Item' not in response:
            # build_idë¡œ ì—†ìœ¼ë©´ idë¡œ ì¡°íšŒ (íˆìŠ¤í† ë¦¬ ë°ì´í„°)
            response = table.get_item(Key={'id': build_id})
        
        if 'Item' not in response:
            # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê¸°ë³¸ ë¬¸ì„œ ìƒì„±
            doc_content = f"""# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ë²• ë¬¸ì„œ

ë¹Œë“œ ID: {build_id}
ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ì‚¬ìš© ë°©ë²•

1. ë¼ì´ë¸ŒëŸ¬ë¦¬ íŒŒì¼ì„ í”„ë¡œì íŠ¸ì— í¬í•¨
2. í•„ìš”í•œ í—¤ë” íŒŒì¼ include
3. í•¨ìˆ˜ í˜¸ì¶œ

## ì£¼ì˜ì‚¬í•­

- ì ì ˆí•œ ëŸ°íƒ€ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë§í¬ í•„ìš”
- ì•„í‚¤í…ì²˜ í˜¸í™˜ì„± í™•ì¸ í•„ìš”
- ë©”ëª¨ë¦¬ ê´€ë¦¬ ì£¼ì˜ (malloc/free, new/delete)
"""
        else:
            build_data = response['Item']
            
            # AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ìƒì„±
            if doc_agent:
                print(f"AIë¡œ ë¬¸ì„œ ìƒì„± ì¤‘... (ë¹Œë“œ ID: {build_id})")
                doc_content = await doc_agent.generate_documentation(build_data)
            else:
                # AI ì—†ìœ¼ë©´ ê¸°ë³¸ ë¬¸ì„œ ìƒì„±
                doc_content = doc_agent._generate_fallback_doc(build_data) if doc_agent else "ë¬¸ì„œ ìƒì„± ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        # ì„ì‹œ íŒŒì¼ë¡œ ë¬¸ì„œ ìƒì„±í•˜ì—¬ ë‹¤ìš´ë¡œë“œ
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8') as tmp_file:
            tmp_file.write(doc_content)
            tmp_file_path = tmp_file.name
        
        return FileResponse(
            tmp_file_path, 
            filename=f"{build_id}_documentation.md", 
            media_type='text/markdown',
            headers={
                "Content-Disposition": f"attachment; filename=\"{build_id}_documentation.md\"",
                "Content-Type": "text/markdown; charset=utf-8"
            }
        )
        
    except Exception as e:
        print(f"ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œì—ë„ ê¸°ë³¸ ë¬¸ì„œ ì œê³µ
        doc_content = f"""# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ë²• ë¬¸ì„œ

ë¹Œë“œ ID: {build_id}

ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
ê¸°ë³¸ ì‚¬ìš©ë²•ì„ ì°¸ê³ í•˜ì„¸ìš”.

## ê¸°ë³¸ ì‚¬ìš© ë°©ë²•

1. ë¼ì´ë¸ŒëŸ¬ë¦¬ íŒŒì¼ì„ í”„ë¡œì íŠ¸ì— í¬í•¨
2. í—¤ë” íŒŒì¼ include
3. í•¨ìˆ˜ í˜¸ì¶œ
"""
        
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8') as tmp_file:
            tmp_file.write(doc_content)
            tmp_file_path = tmp_file.name
        
        return FileResponse(
            tmp_file_path, 
            filename=f"{build_id}_documentation.md",
            media_type='text/markdown',
            headers={
                "Content-Disposition": f"attachment; filename=\"{build_id}_documentation.md\"",
                "Content-Type": "text/markdown; charset=utf-8"
            }
        )

if __name__ == "__main__":
    import uvicorn
    import platform
    
    # í™˜ê²½ ê°ì§€
    is_windows = platform.system() == "Windows"
    
    if is_windows:
        # ìœˆë„ìš° í™˜ê²½
        host = "127.0.0.1"
        print("ğŸš€ ìœˆë„ìš° í™˜ê²½ì—ì„œ ì„œë²„ ì‹œì‘")
    else:
        # AWS/Linux í™˜ê²½
        host = "0.0.0.0"
        print("ğŸš€ AWS/Linux í™˜ê²½ì—ì„œ ì„œë²„ ì‹œì‘")
    
    print("â˜ï¸ í’€ ê¸°ëŠ¥ í™œì„±í™”")
    print(f"ğŸŒ ë¸Œë¼ìš°ì €ì—ì„œ http://localhost ì ‘ì†í•˜ì„¸ìš”")
    uvicorn.run(app, host=host, port=80)
